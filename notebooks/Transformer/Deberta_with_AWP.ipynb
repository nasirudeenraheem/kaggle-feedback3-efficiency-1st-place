{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4f34ef",
   "metadata": {
    "id": "e460cbb5",
    "papermill": {
     "duration": 0.027808,
     "end_time": "2022-03-22T09:40:01.410751",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.382943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "FB3_DEBERTA_FAMILY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec10cc",
   "metadata": {
    "papermill": {
     "duration": 0.024515,
     "end_time": "2022-03-22T09:40:01.460332",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.435817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e7d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.8/site-packages (0.1.22)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.8/site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from opendatasets) (4.62.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from opendatasets) (8.0.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (2.26.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (1.26.12)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kaggle->opendatasets) (2022.5.18.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.8/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (2.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "import opendatasets as od\n",
    "# od.download(\"https://www.kaggle.com/datasets/conjuring92/fpe-tapt-delv3-span-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5db969-614f-4755-a044-9dd05af8e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in /opt/conda/lib/python3.8/site-packages (6.0.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.8/site-packages (from inflect) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic->inflect) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1a81b1-aacb-4d16-a24a-91e8a786aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa5001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.13.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.9.8)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting transformers[sentencepiece]==4.18.0\n",
      "  File was already downloaded /home/transformers-4.18.0-py3-none-any.whl\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  File was already downloaded /home/tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting tqdm>=4.27\n",
      "  File was already downloaded /home/tqdm-4.64.1-py2.py3-none-any.whl\n",
      "Collecting pyyaml>=5.1\n",
      "  File was already downloaded /home/PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  File was already downloaded /home/huggingface_hub-0.9.1-py3-none-any.whl\n",
      "Collecting packaging>=20.0\n",
      "  File was already downloaded /home/packaging-21.3-py3-none-any.whl\n",
      "Collecting requests\n",
      "  File was already downloaded /home/requests-2.28.1-py3-none-any.whl\n",
      "Collecting numpy>=1.17\n",
      "  File was already downloaded /home/numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting sacremoses\n",
      "  File was already downloaded /home/sacremoses-0.0.53.tar.gz\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  File was already downloaded /home/regex-2022.9.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting filelock\n",
      "  File was already downloaded /home/filelock-3.8.0-py3-none-any.whl\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  File was already downloaded /home/sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting protobuf\n",
      "  File was already downloaded /home/protobuf-4.21.6-cp37-abi3-manylinux2014_x86_64.whl\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  File was already downloaded /home/typing_extensions-4.3.0-py3-none-any.whl\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  File was already downloaded /home/pyparsing-3.0.9-py3-none-any.whl\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  File was already downloaded /home/charset_normalizer-2.1.1-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  File was already downloaded /home/idna-3.4-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  File was already downloaded /home/certifi-2022.9.14-py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  File was already downloaded /home/urllib3-1.26.12-py2.py3-none-any.whl\n",
      "Collecting six\n",
      "  File was already downloaded /home/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting click\n",
      "  File was already downloaded /home/click-8.1.3-py3-none-any.whl\n",
      "Collecting joblib\n",
      "  File was already downloaded /home/joblib-1.2.0-py3-none-any.whl\n",
      "Successfully downloaded huggingface-hub numpy packaging pyyaml regex sentencepiece tokenizers tqdm filelock protobuf requests sacremoses transformers certifi charset-normalizer idna pyparsing typing-extensions urllib3 click joblib six\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting tokenizers==0.12.1\n",
      "  File was already downloaded /home/tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Successfully downloaded tokenizers\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.22.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.6.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
      "Requirement already satisfied: torch==1.8.2+cu111 in /opt/conda/lib/python3.8/site-packages (1.8.2+cu111)\n",
      "Requirement already satisfied: torchvision==0.9.2+cu111 in /opt/conda/lib/python3.8/site-packages (0.9.2+cu111)\n",
      "Requirement already satisfied: torchaudio==0.8.2 in /opt/conda/lib/python3.8/site-packages (0.8.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.8.2+cu111) (4.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch==1.8.2+cu111) (1.22.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.9.2+cu111) (9.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bitsandbytes-cuda110\n",
    "!pip install --upgrade wandb\n",
    "!pip download transformers[sentencepiece]==4.18.0\n",
    "!pip download tokenizers==0.12.1\n",
    "!pip3 install -U scikit-learn\n",
    "# !pip install --upgrade torch==1.9.0\n",
    "!pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136ecea",
   "metadata": {
    "id": "1d0c4430",
    "papermill": {
     "duration": 0.024609,
     "end_time": "2022-03-22T09:40:01.576366",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.551757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345ef3f7",
   "metadata": {
    "id": "48dd82bb",
    "papermill": {
     "duration": 0.033949,
     "end_time": "2022-03-22T09:40:01.634977",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.601028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=True\n",
    "    competition='FB3'\n",
    "    _wandb_kernel='harshit-FB3'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    gradient_checkpointing=True\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=8\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_size = 6\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "    train=True\n",
    "    # fc_dropout = 0.0\n",
    "    # fp16 = True\n",
    "    freezing = False\n",
    "    optim8bit = False\n",
    "    gradient_checkpoint = True\n",
    "    awp = True\n",
    "    adv_lr = 5e-5\n",
    "    adv_eps = 0.001\n",
    "    awp_trigger = 0.47\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c0b64f",
   "metadata": {
    "id": "b88c983e",
    "papermill": {
     "duration": 8.873453,
     "end_time": "2022-03-22T09:40:10.532922",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.659469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhmehta1992\u001b[0m (\u001b[33mkaggle-clrp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wandb/run-20220920_051236-1g4x9cxv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-clrp/feedback-public/runs/1g4x9cxv\" target=\"_blank\">microsoft/deberta-v3-large</a></strong> to <a href=\"https://wandb.ai/kaggle-clrp/feedback-public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    \n",
    "    import wandb\n",
    "\n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project='feedback-public', \n",
    "                 name=CFG.model,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.model,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717004d",
   "metadata": {
    "id": "f2ed8ef2",
    "papermill": {
     "duration": 0.038261,
     "end_time": "2022-03-22T09:40:10.626926",
     "exception": false,
     "start_time": "2022-03-22T09:40:10.588665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e775888",
   "metadata": {
    "executionInfo": {
     "elapsed": 20123,
     "status": "ok",
     "timestamp": 1644920080956,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "35916341",
    "outputId": "06fa0ab8-a380-4f54-a98d-b7015b79d9e2",
    "papermill": {
     "duration": 26.143536,
     "end_time": "2022-03-22T09:40:36.798853",
     "exception": false,
     "start_time": "2022-03-22T09:40:10.655317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.8.2+cu111\n",
      "Found existing installation: transformers 4.19.2\n",
      "Uninstalling transformers-4.19.2:\n",
      "  Successfully uninstalled transformers-4.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tokenizers 0.12.1\n",
      "Uninstalling tokenizers-0.12.1:\n",
      "  Successfully uninstalled tokenizers-0.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\n",
      "Processing ./transformers-4.19.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Processing ./tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (0.1.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.8/site-packages (0.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.19.2\n",
      "env: TOKENIZERS_PARALLELISM=true\n",
      "==============================WARNING: DEPRECATED!==============================\n",
      "WARNING! This version of bitsandbytes is deprecated. Please switch to `pip install bitsandbytes` and the new repo: https://github.com/TimDettmers/bitsandbytes\n",
      "==============================WARNING: DEPRECATED!==============================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score, log_loss, mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "\n",
    "print(f\"torch.__version__: {torch.__version__}\")\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('pip uninstall -y tokenizers')\n",
    "os.system('python -m pip install --no-index --find-links=./ transformers')\n",
    "os.system('python -m pip install --no-index --find-links=./ sentencepiece')\n",
    "os.system('python -m pip install --no-index --find-links=./ tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (ContextPooler,\n",
    "                                                                StableDropout)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1828671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n",
    "    \"\"\"\n",
    "    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_types = (\"word\", \"position\", \"token_type\")\n",
    "    for embedding_type in embedding_types:\n",
    "        attr_name = f\"{embedding_type}_embeddings\"\n",
    "        \n",
    "        if hasattr(embeddings_path, attr_name): \n",
    "            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n",
    "                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n",
    "            )\n",
    "            \n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941edc9a",
   "metadata": {
    "id": "fd586614",
    "papermill": {
     "duration": 0.032888,
     "end_time": "2022-03-22T09:40:36.865209",
     "exception": false,
     "start_time": "2022-03-22T09:40:36.832321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73df0149",
   "metadata": {
    "id": "d5c0ccc6",
    "papermill": {
     "duration": 0.21551,
     "end_time": "2022-03-22T09:40:37.116848",
     "exception": false,
     "start_time": "2022-03-22T09:40:36.901338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffbc10",
   "metadata": {
    "id": "cb3d8e1e",
    "papermill": {
     "duration": 0.032614,
     "end_time": "2022-03-22T09:40:37.184739",
     "exception": false,
     "start_time": "2022-03-22T09:40:37.152125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b23f46",
   "metadata": {
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1644920084001,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "bef012d3",
    "outputId": "d4d60dbc-510c-4f34-8d64-dd1d88c4808c",
    "papermill": {
     "duration": 0.154829,
     "end_time": "2022-03-22T09:40:37.374453",
     "exception": false,
     "start_time": "2022-03-22T09:40:37.219624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (3911, 8)\n",
      "test.shape: (3, 2)\n",
      "submission.shape: (3, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
       "0  0000C359D63E       3.0     3.0         3.0          3.0      3.0          3.0\n",
       "1  000BAD50D026       3.0     3.0         3.0          3.0      3.0          3.0\n",
       "2  00367BB2546B       3.0     3.0         3.0          3.0      3.0          3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "INPUT_DIR = \"\"\n",
    "# train = pd.read_csv(INPUT_DIR+'train.csv')\n",
    "train = pd.read_csv(INPUT_DIR+'train.csv')\n",
    "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "print(f\"submission.shape: {submission.shape}\")\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "337c4554-b174-48ee-8743-db7c1f932a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tokens(x):\n",
    "    tok_map = {\n",
    "        k: [\"[{}_start]\".format(p.number_to_words(k)), \"[{}_end]\".format(p.number_to_words(k))]\n",
    "        for k in range(100)\n",
    "    }\n",
    "    appended_text = []\n",
    "    for enumerate_index, row in enumerate(x):\n",
    "        modified = \" \".join([\"[{}_start]\".format(p.number_to_words(enumerate_index)),\\\n",
    "                              row, \"[{}_end]\".format(p.number_to_words(enumerate_index))])\n",
    "        appended_text.append(modified)\n",
    "    essay_text = \"\\n\\n\".join(appended_text)\n",
    "    essay_text = \"[SOE]\" + essay_text + \"[EOE]\"\n",
    "    return essay_text\n",
    "\n",
    "# train['full_text'] = train['full_text'].apply(lambda x: x.split(\"\\n\\n\"))\n",
    "# train['full_text'] = train['full_text'].apply(lambda x: insert_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3726195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "# tokenizer.add_tokens('\\n')\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb18f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.groupby('essay_id').filter(lambda x: len(x) <=13)\n",
    "# train.reset_index(drop=True, inplace = True)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98672592",
   "metadata": {
    "id": "9e05b6c4",
    "papermill": {
     "duration": 0.041734,
     "end_time": "2022-03-22T09:40:39.084284",
     "exception": false,
     "start_time": "2022-03-22T09:40:39.042550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ee5f40-dd85-43a0-99bf-644b633a0d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification==0.1.7 in /opt/conda/lib/python3.8/site-packages (0.1.7)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from iterative-stratification==0.1.7) (1.1.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from iterative-stratification==0.1.7) (1.6.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from iterative-stratification==0.1.7) (1.22.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.1.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "os.system('pip install iterative-stratification==0.1.7')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6718e1b6-3b55-436f-a3f3-38d81e06c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    978\n",
       "1    977\n",
       "2    978\n",
       "3    978\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197d5d98-57a2-4b9a-a2ef-910b41b41be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_length'] = train.apply(lambda x: len(x['full_text']), axis = 1)\n",
    "train.sort_values(by=['text_length'], ascending=False, inplace=True)\n",
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1017bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7373B4F44528</td>\n",
       "      <td>Have you ever accomplished something in your l...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3DCF3E6F4A13</td>\n",
       "      <td>Well most students enjoy summer vacation becau...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04ACA7EB3994</td>\n",
       "      <td>No,I dont think students should attend online ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>6040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9F68BAB4FB63</td>\n",
       "      <td>Students graduated in three year of the High S...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B7FABBC13A0F</td>\n",
       "      <td>\"Character is something what you yourself choo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions  fold  text_length\n",
       "0  7373B4F44528  Have you ever accomplished something in your l...       4.0     4.0         4.0          4.0      3.5          3.5     3         6044\n",
       "1  3DCF3E6F4A13  Well most students enjoy summer vacation becau...       2.0     2.5         3.5          3.0      2.5          3.0     0         6041\n",
       "2  04ACA7EB3994  No,I dont think students should attend online ...       3.5     3.5         4.0          4.0      3.5          3.5     2         6040\n",
       "3  9F68BAB4FB63  Students graduated in three year of the High S...       3.0     3.5         3.0          3.0      3.0          3.5     0         6031\n",
       "4  B7FABBC13A0F  \"Character is something what you yourself choo...       3.5     3.0         3.5          3.0      3.5          3.0     0         6031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba20c634",
   "metadata": {
    "id": "4c3ce877",
    "papermill": {
     "duration": 0.049441,
     "end_time": "2022-03-22T09:40:39.291307",
     "exception": false,
     "start_time": "2022-03-22T09:40:39.241866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    display(train.groupby('fold').size())\n",
    "    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n",
    "    display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc80ec",
   "metadata": {
    "id": "14da40cf",
    "papermill": {
     "duration": 0.04897,
     "end_time": "2022-03-22T09:40:44.706931",
     "exception": false,
     "start_time": "2022-03-22T09:40:44.657961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a8b160",
   "metadata": {
    "executionInfo": {
     "elapsed": 32827,
     "status": "ok",
     "timestamp": 1644920122500,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "c00327b0",
    "outputId": "26e947da-b73a-494d-e776-906b037ac08a",
    "papermill": {
     "duration": 7.208379,
     "end_time": "2022-03-22T09:40:51.959343",
     "exception": false,
     "start_time": "2022-03-22T09:40:44.750964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5addc7cb0324867b14e40c0a1b65f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 1429\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "lengths = []\n",
    "tk0 = tqdm(train['full_text'].fillna(\"\").values, total=len(train))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "CFG.max_len = max(lengths) + 3 # cls & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e532cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1d1ddd8-71d3-4d51-b41f-561cf2ac828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24a1c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWP:\n",
    "    \"\"\"Implements weighted adverserial perturbation\n",
    "    adapted from: https://www.kaggle.com/code/wht1996/feedback-nn-train/notebook\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, adv_param=\"weight\", adv_lr=1, adv_eps=0.001):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "\n",
    "    def attack_backward(self, batch, labels):\n",
    "        if self.adv_lr == 0:\n",
    "            return\n",
    "        self._save()\n",
    "        self._attack_step()\n",
    "\n",
    "        y_preds, metric, loss = self.model(batch, targets = labels)\n",
    "        loss = loss.mean()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._restore()\n",
    "\n",
    "    def _attack_step(self):\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
    "                    )\n",
    "\n",
    "    def _save(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps,\n",
    "                    )\n",
    "\n",
    "    def _restore(self,):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7a4c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Re-initialization ------------------------------------------------------#\n",
    "def reinit_deberta(base_model, num_reinit_layers):\n",
    "    config = base_model.config\n",
    "\n",
    "    for layer in base_model.encoder.layer[-num_reinit_layers:]:\n",
    "        for module in layer.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "                if module.padding_idx is not None:\n",
    "                    module.weight.data[module.padding_idx].zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8b8ded",
   "metadata": {
    "id": "9f791a19",
    "papermill": {
     "duration": 0.055528,
     "end_time": "2022-03-22T09:40:52.072178",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.016650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['full_text'].values\n",
    "        self.labels = df[CFG.target_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.cfg.tokenizer.encode_plus(\n",
    "                        self.text[item],\n",
    "                        truncation=True,\n",
    "                        return_token_type_ids=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.cfg.max_len\n",
    "                    )\n",
    "        samples = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "\n",
    "        if 'token_type_ids' in inputs:\n",
    "            samples['token_type_ids'] = inputs['token_type_ids']\n",
    "            \n",
    "        samples['target'] = self.labels[item]\n",
    "            \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90668fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataCollatorWithPadding(DataCollatorWithPadding):\n",
    "    \"\"\"\n",
    "    data collector for seq classification\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = None\n",
    "    padding = True\n",
    "    max_length = None\n",
    "    pad_to_multiple_of = None\n",
    "    return_tensors = \"pt\"\n",
    "\n",
    "    def __call__(self, features):\n",
    "        labels = None\n",
    "        if \"target\" in features[0].keys():\n",
    "            labels = [feature[\"target\"] for feature in features]\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        if labels is not None:\n",
    "            batch[\"target\"] = labels\n",
    "\n",
    "        batch = {k: (torch.tensor(v, dtype=torch.float32) if k in [\"target\", \"aux_labels\"] else torch.tensor(\n",
    "            v, dtype=torch.int64)) for k, v in batch.items()}\n",
    "        return batch\n",
    "\n",
    "collate_fn = CustomDataCollatorWithPadding(tokenizer=CFG.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfea193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPEPooler(nn.Module):\n",
    "    \"\"\"Parameter free pooler to get sentence embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pooler_type):\n",
    "        super().__init__()\n",
    "        self.pooler_type = pooler_type\n",
    "        assert pooler_type in [\"cls\", \"mean\", \"mean_top2\", \"mean_first_last\"]\n",
    "\n",
    "    def forward(self, outputs, mask):\n",
    "        last_hidden = outputs[\"last_hidden_state\"]\n",
    "        hidden_states = outputs[\"hidden_states\"]\n",
    "\n",
    "        if self.pooler_type == \"cls\":\n",
    "            return last_hidden[:, 0]  # [CLS] output\n",
    "\n",
    "        elif self.pooler_type == \"mean\":\n",
    "            input_mask_expanded = mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
    "            sum_embeddings = torch.sum(last_hidden * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1)\n",
    "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "            mean_embeddings = sum_embeddings / sum_mask\n",
    "            return mean_embeddings\n",
    "\n",
    "        elif self.pooler_type == \"mean_first_last\":\n",
    "            first_hidden = hidden_states[0]\n",
    "            last_hidden = hidden_states[-1]\n",
    "            pooled_result = ((first_hidden + last_hidden) / 2.0 * mask.unsqueeze(-1)\n",
    "                             ).sum(1) / mask.sum(-1).unsqueeze(-1)\n",
    "            return pooled_result\n",
    "\n",
    "        elif self.pooler_type == \"mean_top2\":\n",
    "            second_last_hidden = hidden_states[-2]\n",
    "            last_hidden = hidden_states[-1]\n",
    "            pooled_result = ((last_hidden + second_last_hidden) / 2.0 * mask.unsqueeze(-1)\n",
    "                             ).sum(1) / mask.sum(-1).unsqueeze(-1)\n",
    "            return pooled_result\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25551f03",
   "metadata": {
    "id": "e04d6363",
    "papermill": {
     "duration": 0.044161,
     "end_time": "2022-03-22T09:40:52.262022",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.217861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c303701",
   "metadata": {
    "id": "4c5bab44",
    "papermill": {
     "duration": 0.066203,
     "end_time": "2022-03-22T09:40:52.372030",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.305827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        self.config.hidden_dropout = 0.\n",
    "        self.config.hidden_dropout_prob = 0.\n",
    "        self.config.attention_dropout = 0.\n",
    "        self.config.attention_probs_dropout_prob = 0.\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(config=self.config)\n",
    "            \n",
    "        ########################### resize ############################\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        # self.mean_pooler = FPEPooler(pooler_type=\"mean\")\n",
    "        # self.cls_pooler = ContextPooler(self.model.config)\n",
    "        \n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        \n",
    "#         self.normal1 = nn.LayerNorm(self.config.hidden_size*2)\n",
    "#         LSTM_SIZE = self.config.hidden_size\n",
    "#         self.Lstm = nn.LSTM(self.config.hidden_size, LSTM_SIZE // 2,\n",
    "#                             bidirectional=True, batch_first=True)  # , num_layers=2\n",
    "        \n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if cfg.freezing:\n",
    "                freeze(self.model.embeddings)\n",
    "                freeze(self.model.encoder.layer[:2])\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if cfg.gradient_checkpoint:\n",
    "            self.model.gradient_checkpointing_enable()  \n",
    "        \n",
    "    def loss(self, outputs, targets):\n",
    "        loss_fct = nn.MSELoss(reduction='mean')\n",
    "        loss = loss_fct(outputs, targets)\n",
    "        return loss\n",
    "    \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        device = targets.get_device()\n",
    "\n",
    "        mll = MCRMSE(\n",
    "            targets.cpu().detach().numpy(),\n",
    "            outputs.cpu().detach().numpy())\n",
    "        return mll\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, batch, targets=None):\n",
    "        \n",
    "        \"\"\"forward pass through the model\n",
    "        \"\"\"\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        \n",
    "        transformer_out = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        last_hidden_state = transformer_out['last_hidden_state']\n",
    "        \n",
    "        mean_pooled_output = self.pooler(last_hidden_state, attention_mask)\n",
    "        # cls_pooled_output = self.cls_pooler(transformer_out[\"last_hidden_state\"])\n",
    "        # cls_pooled_output = self.fc_dropout(cls_pooled_output)\n",
    "        # sequence_output = torch.cat([mean_pooled_output, cls_pooled_output], dim=1)\n",
    "        \n",
    "        ######################## hidden state ###################\n",
    "#         sequence_output = transformer_out[0]\n",
    "        ############################ mean of all tokens ####################\n",
    "        \n",
    "        # sequence_output_mean = torch.mean(transformer_out[0], dim=1)\n",
    "        # sequence_output_max = torch.max(transformer_out[0], dim=1)\n",
    "        \n",
    "#         self.Lstm.flatten_parameters()\n",
    "#         lstm_output, _ = self.Lstm(sequence_output)\n",
    "#         sequence_output = torch.cat((sequence_output, lstm_output), 2)\n",
    "#         sequence_output = self.normal1(sequence_output)\n",
    "#         sequence_output = sequence_output[:,0,:]\n",
    "        \n",
    "        ########################## concat ############################\n",
    "        # sequence_output = torch.cat((sequence_output_mean, sequence_output_max, sequence_output), dim=1)\n",
    "        \n",
    "        # sequence_output = transformer_out.last_hidden_state\n",
    "        # sequence_output = self.pooler(sequence_output, mask)\n",
    "        # sequence_output = self.fc_dropout(sequence_output)\n",
    "\n",
    "        # Main task\n",
    "        logits = self.fc(mean_pooled_output)\n",
    "\n",
    "        if targets is not None:\n",
    "            metric = self.monitor_metrics(logits, targets)\n",
    "            \n",
    "            loss = self.loss(logits, targets)\n",
    "            \n",
    "            return logits, metric, loss\n",
    "        \n",
    "        return logits, 0., 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3454549",
   "metadata": {
    "id": "deee9675",
    "papermill": {
     "duration": 0.044158,
     "end_time": "2022-03-22T09:40:52.460401",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.416243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helpler functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62df556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWP_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56b70f5d",
   "metadata": {
    "id": "c8263b0c",
    "papermill": {
     "duration": 0.078567,
     "end_time": "2022-03-22T09:40:52.582474",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.503907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    if CFG.awp:    \n",
    "        print('Enable AWP')\n",
    "        awp = AWP(model, optimizer, adv_lr = CFG.adv_lr, adv_eps = CFG.adv_eps)\n",
    "        assert CFG.gradient_accumulation_steps == 1, \"Grad accumulation not supported with AWP\"\n",
    "    \n",
    "    for step, samples in enumerate(train_loader):\n",
    "        labels = samples['target'].to(device, dtype = torch.float32)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds, metric, loss = model(samples, targets = labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        if AWP_FLAG:\n",
    "            print('attacking')\n",
    "            awp.attack_backward(samples, labels)\n",
    "        \n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, samples in enumerate(valid_loader):\n",
    "        labels = samples['target'].to(device, dtype = torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds, metric, loss = model(samples, targets = labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff603f7d",
   "metadata": {
    "id": "bed940e1",
    "papermill": {
     "duration": 0.071348,
     "end_time": "2022-03-22T09:40:52.697940",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.626592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,collate_fn = collate_fn,\n",
    "                              shuffle=True,num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,collate_fn = collate_fn,\n",
    "                              shuffle=False,num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path = None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n and p.requires_grad],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    if CFG.gradient_checkpoint:\n",
    "        optimizer = bnb.optim.AdamW(optimizer_parameters, lr=CFG.encoder_lr, optim_bits=8)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, device)\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, predictions)[0]\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "            \n",
    "        if (CFG.awp) & ( best_score <= CFG.awp_trigger):\n",
    "            print(\"AWP is triggered...\")\n",
    "            AWP_FLAG = True\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[\"pred_\" + c for c in labels]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "703218cf",
   "metadata": {
    "id": "6cc76b1e",
    "papermill": {
     "duration": 30265.411984,
     "end_time": "2022-03-22T18:05:18.155447",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.743463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [1][0/366] Elapsed 0m 3s (remain 19m 14s) Loss: 10.1917(10.1917) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/366] Elapsed 0m 34s (remain 9m 23s) Loss: 0.4879(4.2712) Grad: 33850.6875  LR: 0.00001999  \n",
      "Epoch: [1][40/366] Elapsed 1m 8s (remain 9m 1s) Loss: 0.3361(2.3648) Grad: 12560.1680  LR: 0.00001996  \n",
      "Epoch: [1][60/366] Elapsed 1m 33s (remain 7m 46s) Loss: 0.2055(1.6835) Grad: 9609.3779  LR: 0.00001991  \n",
      "Epoch: [1][80/366] Elapsed 2m 3s (remain 7m 15s) Loss: 0.2418(1.3451) Grad: 15006.6885  LR: 0.00001985  \n",
      "Epoch: [1][100/366] Elapsed 2m 36s (remain 6m 49s) Loss: 0.1663(1.1336) Grad: 8219.6982  LR: 0.00001977  \n",
      "Epoch: [1][120/366] Elapsed 3m 8s (remain 6m 22s) Loss: 0.3977(1.0006) Grad: 27848.4570  LR: 0.00001967  \n",
      "Epoch: [1][140/366] Elapsed 3m 43s (remain 5m 56s) Loss: 0.3617(0.8999) Grad: 29621.0078  LR: 0.00001955  \n",
      "Epoch: [1][160/366] Elapsed 4m 12s (remain 5m 20s) Loss: 0.3841(0.8238) Grad: 32502.8945  LR: 0.00001941  \n",
      "Epoch: [1][180/366] Elapsed 4m 40s (remain 4m 47s) Loss: 0.2157(0.7641) Grad: 24829.3613  LR: 0.00001926  \n",
      "Epoch: [1][200/366] Elapsed 5m 11s (remain 4m 15s) Loss: 0.2304(0.7130) Grad: 19005.9082  LR: 0.00001909  \n",
      "Epoch: [1][220/366] Elapsed 5m 41s (remain 3m 44s) Loss: 0.2496(0.6759) Grad: 16751.4902  LR: 0.00001890  \n",
      "Epoch: [1][240/366] Elapsed 6m 16s (remain 3m 15s) Loss: 0.2274(0.6371) Grad: 10363.4170  LR: 0.00001870  \n",
      "Epoch: [1][260/366] Elapsed 6m 47s (remain 2m 44s) Loss: 0.1957(0.6047) Grad: 11111.4639  LR: 0.00001848  \n",
      "Epoch: [1][280/366] Elapsed 7m 19s (remain 2m 12s) Loss: 0.3250(0.5820) Grad: 10671.0488  LR: 0.00001824  \n",
      "Epoch: [1][300/366] Elapsed 7m 49s (remain 1m 41s) Loss: 0.2329(0.5586) Grad: 7452.2808  LR: 0.00001799  \n",
      "Epoch: [1][320/366] Elapsed 8m 21s (remain 1m 10s) Loss: 0.1954(0.5378) Grad: 13482.0195  LR: 0.00001773  \n",
      "Epoch: [1][340/366] Elapsed 8m 50s (remain 0m 38s) Loss: 0.2241(0.5201) Grad: 12748.8135  LR: 0.00001745  \n",
      "Epoch: [1][360/366] Elapsed 9m 18s (remain 0m 7s) Loss: 0.3556(0.5049) Grad: 11216.6240  LR: 0.00001715  \n",
      "Epoch: [1][365/366] Elapsed 9m 25s (remain 0m 0s) Loss: 0.2082(0.5015) Grad: 13120.3906  LR: 0.00001708  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 7s) Loss: 0.2402(0.2402) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 14s) Loss: 0.1754(0.2410) \n",
      "EVAL: [40/123] Elapsed 0m 22s (remain 0m 45s) Loss: 0.2343(0.2344) \n",
      "EVAL: [60/123] Elapsed 0m 28s (remain 0m 28s) Loss: 0.1760(0.2276) \n",
      "EVAL: [80/123] Elapsed 0m 32s (remain 0m 16s) Loss: 0.3598(0.2249) \n",
      "EVAL: [100/123] Elapsed 0m 35s (remain 0m 7s) Loss: 0.1945(0.2213) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5015  avg_val_loss: 0.2170  time: 604s\n",
      "Epoch 1 - Score: 0.4647\n",
      "Epoch 1 - Save Best Score: 0.4647 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1363(0.2175) \n",
      "EVAL: [122/123] Elapsed 0m 38s (remain 0m 0s) Loss: 0.1614(0.2170) \n",
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [2][0/366] Elapsed 0m 0s (remain 5m 52s) Loss: 0.1642(0.1642) Grad: 240960.8906  LR: 0.00001706  \n",
      "Epoch: [2][20/366] Elapsed 0m 32s (remain 8m 49s) Loss: 0.2808(0.2275) Grad: 520041.6250  LR: 0.00001675  \n",
      "Epoch: [2][40/366] Elapsed 1m 3s (remain 8m 24s) Loss: 0.2500(0.2372) Grad: 507427.9062  LR: 0.00001643  \n",
      "Epoch: [2][60/366] Elapsed 1m 33s (remain 7m 48s) Loss: 0.1985(0.2202) Grad: 453241.8438  LR: 0.00001610  \n",
      "Epoch: [2][80/366] Elapsed 2m 6s (remain 7m 25s) Loss: 0.1342(0.2075) Grad: 235912.0625  LR: 0.00001575  \n",
      "Epoch: [2][100/366] Elapsed 2m 42s (remain 7m 6s) Loss: 0.2679(0.2066) Grad: 384661.1562  LR: 0.00001540  \n",
      "Epoch: [2][120/366] Elapsed 3m 12s (remain 6m 29s) Loss: 0.1589(0.2025) Grad: 255898.6406  LR: 0.00001503  \n",
      "Epoch: [2][140/366] Elapsed 3m 51s (remain 6m 9s) Loss: 0.2105(0.1965) Grad: 586213.8125  LR: 0.00001466  \n",
      "Epoch: [2][160/366] Elapsed 4m 24s (remain 5m 36s) Loss: 0.1228(0.1931) Grad: 201645.3281  LR: 0.00001427  \n",
      "Epoch: [2][180/366] Elapsed 4m 51s (remain 4m 58s) Loss: 0.2032(0.1915) Grad: 175800.2500  LR: 0.00001388  \n",
      "Epoch: [2][200/366] Elapsed 5m 21s (remain 4m 24s) Loss: 0.1903(0.1894) Grad: 323847.8438  LR: 0.00001348  \n",
      "Epoch: [2][220/366] Elapsed 5m 55s (remain 3m 53s) Loss: 0.1617(0.1899) Grad: 285553.7812  LR: 0.00001308  \n",
      "Epoch: [2][240/366] Elapsed 6m 28s (remain 3m 21s) Loss: 0.1937(0.1896) Grad: 270175.5938  LR: 0.00001267  \n",
      "Epoch: [2][260/366] Elapsed 6m 58s (remain 2m 48s) Loss: 0.1957(0.1880) Grad: 170747.9531  LR: 0.00001225  \n",
      "Epoch: [2][280/366] Elapsed 7m 33s (remain 2m 17s) Loss: 0.1785(0.1870) Grad: 318834.7812  LR: 0.00001183  \n",
      "Epoch: [2][300/366] Elapsed 8m 1s (remain 1m 43s) Loss: 0.1498(0.1856) Grad: 252082.4688  LR: 0.00001141  \n",
      "Epoch: [2][320/366] Elapsed 8m 36s (remain 1m 12s) Loss: 0.2653(0.1850) Grad: 350476.4688  LR: 0.00001098  \n",
      "Epoch: [2][340/366] Elapsed 9m 8s (remain 0m 40s) Loss: 0.1903(0.1852) Grad: 386627.5312  LR: 0.00001056  \n",
      "Epoch: [2][360/366] Elapsed 9m 35s (remain 0m 7s) Loss: 0.1620(0.1850) Grad: 219288.0000  LR: 0.00001013  \n",
      "Epoch: [2][365/366] Elapsed 9m 45s (remain 0m 0s) Loss: 0.1383(0.1846) Grad: 379161.5000  LR: 0.00001002  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 6s) Loss: 0.2344(0.2344) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 14s) Loss: 0.1931(0.2235) \n",
      "EVAL: [40/123] Elapsed 0m 22s (remain 0m 45s) Loss: 0.2072(0.2206) \n",
      "EVAL: [60/123] Elapsed 0m 28s (remain 0m 28s) Loss: 0.1762(0.2144) \n",
      "EVAL: [80/123] Elapsed 0m 32s (remain 0m 16s) Loss: 0.3351(0.2122) \n",
      "EVAL: [100/123] Elapsed 0m 35s (remain 0m 7s) Loss: 0.1758(0.2087) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1846  avg_val_loss: 0.2049  time: 624s\n",
      "Epoch 2 - Score: 0.4519\n",
      "Epoch 2 - Save Best Score: 0.4519 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1382(0.2052) \n",
      "EVAL: [122/123] Elapsed 0m 38s (remain 0m 0s) Loss: 0.1805(0.2049) \n",
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [3][0/366] Elapsed 0m 1s (remain 9m 15s) Loss: 0.2401(0.2401) Grad: 374140.5312  LR: 0.00001000  \n",
      "Epoch: [3][20/366] Elapsed 0m 36s (remain 10m 2s) Loss: 0.2364(0.1778) Grad: 504284.6875  LR: 0.00000957  \n",
      "Epoch: [3][40/366] Elapsed 1m 7s (remain 8m 51s) Loss: 0.1938(0.1689) Grad: 258093.1875  LR: 0.00000914  \n",
      "Epoch: [3][60/366] Elapsed 1m 35s (remain 7m 58s) Loss: 0.1213(0.1731) Grad: 305032.1250  LR: 0.00000872  \n",
      "Epoch: [3][80/366] Elapsed 2m 3s (remain 7m 15s) Loss: 0.1123(0.1691) Grad: 218716.8750  LR: 0.00000829  \n",
      "Epoch: [3][100/366] Elapsed 2m 29s (remain 6m 32s) Loss: 0.1879(0.1723) Grad: 408998.9688  LR: 0.00000787  \n",
      "Epoch: [3][120/366] Elapsed 3m 2s (remain 6m 9s) Loss: 0.1758(0.1741) Grad: 360577.0312  LR: 0.00000746  \n",
      "Epoch: [3][140/366] Elapsed 3m 33s (remain 5m 41s) Loss: 0.2081(0.1772) Grad: 227195.1875  LR: 0.00000704  \n",
      "Epoch: [3][160/366] Elapsed 4m 0s (remain 5m 6s) Loss: 0.3390(0.1750) Grad: 659911.3125  LR: 0.00000664  \n",
      "Epoch: [3][180/366] Elapsed 4m 29s (remain 4m 34s) Loss: 0.1482(0.1737) Grad: 248883.7344  LR: 0.00000624  \n",
      "Epoch: [3][200/366] Elapsed 5m 2s (remain 4m 8s) Loss: 0.1639(0.1735) Grad: 360602.6875  LR: 0.00000584  \n",
      "Epoch: [3][220/366] Elapsed 5m 38s (remain 3m 41s) Loss: 0.2263(0.1735) Grad: 449621.7812  LR: 0.00000546  \n",
      "Epoch: [3][240/366] Elapsed 6m 8s (remain 3m 10s) Loss: 0.1560(0.1739) Grad: 298771.2812  LR: 0.00000508  \n",
      "Epoch: [3][260/366] Elapsed 6m 46s (remain 2m 43s) Loss: 0.2102(0.1750) Grad: 246980.0781  LR: 0.00000471  \n",
      "Epoch: [3][280/366] Elapsed 7m 15s (remain 2m 11s) Loss: 0.1290(0.1735) Grad: 268091.6562  LR: 0.00000435  \n",
      "Epoch: [3][300/366] Elapsed 7m 53s (remain 1m 42s) Loss: 0.1872(0.1744) Grad: 327036.0625  LR: 0.00000400  \n",
      "Epoch: [3][320/366] Elapsed 8m 28s (remain 1m 11s) Loss: 0.1498(0.1743) Grad: 278280.1250  LR: 0.00000367  \n",
      "Epoch: [3][340/366] Elapsed 9m 2s (remain 0m 39s) Loss: 0.1591(0.1740) Grad: 272761.8438  LR: 0.00000334  \n",
      "Epoch: [3][360/366] Elapsed 9m 29s (remain 0m 7s) Loss: 0.2479(0.1742) Grad: 257649.0469  LR: 0.00000303  \n",
      "Epoch: [3][365/366] Elapsed 9m 37s (remain 0m 0s) Loss: 0.1476(0.1747) Grad: 207770.3125  LR: 0.00000295  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 4s) Loss: 0.2404(0.2404) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 14s) Loss: 0.2023(0.2217) \n",
      "EVAL: [40/123] Elapsed 0m 22s (remain 0m 45s) Loss: 0.2050(0.2197) \n",
      "EVAL: [60/123] Elapsed 0m 28s (remain 0m 28s) Loss: 0.1760(0.2132) \n",
      "EVAL: [80/123] Elapsed 0m 32s (remain 0m 16s) Loss: 0.3301(0.2110) \n",
      "EVAL: [100/123] Elapsed 0m 35s (remain 0m 7s) Loss: 0.1773(0.2077) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1747  avg_val_loss: 0.2039  time: 616s\n",
      "Epoch 3 - Score: 0.4508\n",
      "Epoch 3 - Save Best Score: 0.4508 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1365(0.2043) \n",
      "EVAL: [122/123] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1844(0.2039) \n",
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [4][0/366] Elapsed 0m 1s (remain 10m 46s) Loss: 0.1616(0.1616) Grad: 308449.0625  LR: 0.00000294  \n",
      "Epoch: [4][20/366] Elapsed 0m 31s (remain 8m 29s) Loss: 0.1332(0.1741) Grad: 221256.4219  LR: 0.00000264  \n",
      "Epoch: [4][40/366] Elapsed 0m 59s (remain 7m 54s) Loss: 0.1467(0.1681) Grad: 256623.5156  LR: 0.00000236  \n",
      "Epoch: [4][60/366] Elapsed 1m 32s (remain 7m 44s) Loss: 0.1717(0.1692) Grad: 185645.2812  LR: 0.00000209  \n",
      "Epoch: [4][80/366] Elapsed 2m 7s (remain 7m 27s) Loss: 0.1504(0.1720) Grad: 253456.9062  LR: 0.00000183  \n",
      "Epoch: [4][100/366] Elapsed 2m 40s (remain 7m 1s) Loss: 0.1578(0.1718) Grad: 333248.5938  LR: 0.00000159  \n",
      "Epoch: [4][120/366] Elapsed 3m 14s (remain 6m 34s) Loss: 0.1921(0.1720) Grad: 411478.5312  LR: 0.00000137  \n",
      "Epoch: [4][140/366] Elapsed 3m 45s (remain 5m 59s) Loss: 0.2875(0.1730) Grad: 300794.0625  LR: 0.00000116  \n",
      "Epoch: [4][160/366] Elapsed 4m 15s (remain 5m 24s) Loss: 0.2263(0.1723) Grad: 290695.8750  LR: 0.00000097  \n",
      "Epoch: [4][180/366] Elapsed 4m 44s (remain 4m 50s) Loss: 0.1761(0.1719) Grad: 236586.8438  LR: 0.00000079  \n",
      "Epoch: [4][200/366] Elapsed 5m 12s (remain 4m 16s) Loss: 0.1194(0.1714) Grad: 195758.6875  LR: 0.00000063  \n",
      "Epoch: [4][220/366] Elapsed 5m 51s (remain 3m 50s) Loss: 0.1493(0.1728) Grad: 215245.8281  LR: 0.00000049  \n",
      "Epoch: [4][240/366] Elapsed 6m 25s (remain 3m 20s) Loss: 0.2350(0.1731) Grad: 514604.1250  LR: 0.00000037  \n",
      "Epoch: [4][260/366] Elapsed 6m 58s (remain 2m 48s) Loss: 0.1985(0.1731) Grad: 271253.0938  LR: 0.00000026  \n",
      "Epoch: [4][280/366] Elapsed 7m 24s (remain 2m 14s) Loss: 0.1907(0.1722) Grad: 240740.5781  LR: 0.00000017  \n",
      "Epoch: [4][300/366] Elapsed 7m 58s (remain 1m 43s) Loss: 0.1641(0.1719) Grad: 228949.7500  LR: 0.00000010  \n",
      "Epoch: [4][320/366] Elapsed 8m 40s (remain 1m 12s) Loss: 0.2353(0.1718) Grad: 415329.5625  LR: 0.00000005  \n",
      "Epoch: [4][340/366] Elapsed 9m 6s (remain 0m 40s) Loss: 0.1243(0.1712) Grad: 289763.8750  LR: 0.00000002  \n",
      "Epoch: [4][360/366] Elapsed 9m 35s (remain 0m 7s) Loss: 0.1192(0.1716) Grad: 232965.6562  LR: 0.00000000  \n",
      "Epoch: [4][365/366] Elapsed 9m 41s (remain 0m 0s) Loss: 0.2240(0.1717) Grad: 241991.5938  LR: 0.00000000  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 5s) Loss: 0.2429(0.2429) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 14s) Loss: 0.2070(0.2220) \n",
      "EVAL: [40/123] Elapsed 0m 22s (remain 0m 45s) Loss: 0.2048(0.2200) \n",
      "EVAL: [60/123] Elapsed 0m 28s (remain 0m 28s) Loss: 0.1776(0.2128) \n",
      "EVAL: [80/123] Elapsed 0m 32s (remain 0m 16s) Loss: 0.3258(0.2104) \n",
      "EVAL: [100/123] Elapsed 0m 35s (remain 0m 7s) Loss: 0.1755(0.2071) \n",
      "EVAL: [120/123] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1382(0.2037) \n",
      "EVAL: [122/123] Elapsed 0m 38s (remain 0m 0s) Loss: 0.1860(0.2034) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1717  avg_val_loss: 0.2034  time: 620s\n",
      "Epoch 4 - Score: 0.4503\n",
      "Epoch 4 - Save Best Score: 0.4503 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.4503\n",
      "========== fold: 1 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [1][0/366] Elapsed 0m 1s (remain 11m 34s) Loss: 10.7395(10.7395) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/366] Elapsed 0m 38s (remain 10m 31s) Loss: 0.4704(4.0655) Grad: 27088.2070  LR: 0.00001999  \n",
      "Epoch: [1][40/366] Elapsed 1m 5s (remain 8m 40s) Loss: 0.2882(2.2394) Grad: 22603.0352  LR: 0.00001996  \n",
      "Epoch: [1][60/366] Elapsed 1m 36s (remain 8m 1s) Loss: 0.2920(1.6171) Grad: 15251.3701  LR: 0.00001991  \n",
      "Epoch: [1][80/366] Elapsed 2m 0s (remain 7m 5s) Loss: 0.3069(1.2919) Grad: 15493.1484  LR: 0.00001985  \n",
      "Epoch: [1][100/366] Elapsed 2m 31s (remain 6m 38s) Loss: 0.1885(1.0940) Grad: 18038.7754  LR: 0.00001977  \n",
      "Epoch: [1][120/366] Elapsed 3m 1s (remain 6m 7s) Loss: 0.4115(0.9554) Grad: 24890.7168  LR: 0.00001967  \n",
      "Epoch: [1][140/366] Elapsed 3m 29s (remain 5m 34s) Loss: 0.2545(0.8651) Grad: 16426.5254  LR: 0.00001955  \n",
      "Epoch: [1][160/366] Elapsed 4m 2s (remain 5m 8s) Loss: 0.2857(0.7950) Grad: 23770.7852  LR: 0.00001941  \n",
      "Epoch: [1][180/366] Elapsed 4m 32s (remain 4m 38s) Loss: 0.1630(0.7333) Grad: 8132.3081  LR: 0.00001926  \n",
      "Epoch: [1][200/366] Elapsed 5m 1s (remain 4m 7s) Loss: 0.2214(0.6838) Grad: 7150.7607  LR: 0.00001909  \n",
      "Epoch: [1][220/366] Elapsed 5m 39s (remain 3m 42s) Loss: 0.2315(0.6448) Grad: 11350.3184  LR: 0.00001890  \n",
      "Epoch: [1][240/366] Elapsed 6m 12s (remain 3m 13s) Loss: 0.2820(0.6092) Grad: 12075.9434  LR: 0.00001870  \n",
      "Epoch: [1][260/366] Elapsed 6m 43s (remain 2m 42s) Loss: 0.3225(0.5862) Grad: 17818.5957  LR: 0.00001848  \n",
      "Epoch: [1][280/366] Elapsed 7m 10s (remain 2m 10s) Loss: 0.2326(0.5592) Grad: 9938.3311  LR: 0.00001824  \n",
      "Epoch: [1][300/366] Elapsed 7m 46s (remain 1m 40s) Loss: 0.1896(0.5372) Grad: 9804.2861  LR: 0.00001799  \n",
      "Epoch: [1][320/366] Elapsed 8m 14s (remain 1m 9s) Loss: 0.3095(0.5184) Grad: 21148.8047  LR: 0.00001773  \n",
      "Epoch: [1][340/366] Elapsed 8m 50s (remain 0m 38s) Loss: 0.1440(0.5013) Grad: 12364.9932  LR: 0.00001745  \n",
      "Epoch: [1][360/366] Elapsed 9m 23s (remain 0m 7s) Loss: 0.1982(0.4863) Grad: 6299.5547  LR: 0.00001716  \n",
      "Epoch: [1][365/366] Elapsed 9m 33s (remain 0m 0s) Loss: 0.2563(0.4834) Grad: 11414.7354  LR: 0.00001708  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 41s) Loss: 0.1468(0.1468) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 17s) Loss: 0.2265(0.2429) \n",
      "EVAL: [40/123] Elapsed 0m 23s (remain 0m 47s) Loss: 0.2725(0.2325) \n",
      "EVAL: [60/123] Elapsed 0m 29s (remain 0m 29s) Loss: 0.2079(0.2332) \n",
      "EVAL: [80/123] Elapsed 0m 33s (remain 0m 17s) Loss: 0.1670(0.2243) \n",
      "EVAL: [100/123] Elapsed 0m 37s (remain 0m 8s) Loss: 0.1810(0.2229) \n",
      "EVAL: [120/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.1499(0.2217) \n",
      "EVAL: [122/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.0591(0.2218) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4834  avg_val_loss: 0.2218  time: 613s\n",
      "Epoch 1 - Score: 0.4706\n",
      "Epoch 1 - Save Best Score: 0.4706 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [2][0/366] Elapsed 0m 1s (remain 9m 53s) Loss: 0.2058(0.2058) Grad: 396383.8125  LR: 0.00001707  \n",
      "Epoch: [2][20/366] Elapsed 0m 29s (remain 7m 56s) Loss: 0.7823(0.4753) Grad: 345614.4688  LR: 0.00001676  \n",
      "Epoch: [2][40/366] Elapsed 0m 58s (remain 7m 44s) Loss: 0.2153(0.4084) Grad: 51828.1250  LR: 0.00001644  \n",
      "Epoch: [2][60/366] Elapsed 1m 30s (remain 7m 34s) Loss: 0.1748(0.3405) Grad: 59628.2734  LR: 0.00001610  \n",
      "Epoch: [2][80/366] Elapsed 2m 5s (remain 7m 19s) Loss: 0.1254(0.3015) Grad: 25977.3125  LR: 0.00001576  \n",
      "Epoch: [2][100/366] Elapsed 2m 37s (remain 6m 54s) Loss: 0.1996(0.2741) Grad: 67793.1094  LR: 0.00001540  \n",
      "Epoch: [2][120/366] Elapsed 3m 14s (remain 6m 33s) Loss: 0.1779(0.2627) Grad: 58554.0664  LR: 0.00001504  \n",
      "Epoch: [2][140/366] Elapsed 3m 44s (remain 5m 57s) Loss: 0.1746(0.2520) Grad: 94003.2969  LR: 0.00001466  \n",
      "Epoch: [2][160/366] Elapsed 4m 15s (remain 5m 25s) Loss: 0.1471(0.2426) Grad: 64535.3750  LR: 0.00001428  \n",
      "Epoch: [2][180/366] Elapsed 4m 48s (remain 4m 54s) Loss: 0.1783(0.2366) Grad: 79981.9375  LR: 0.00001389  \n",
      "Epoch: [2][200/366] Elapsed 5m 12s (remain 4m 16s) Loss: 0.2185(0.2302) Grad: 78360.7031  LR: 0.00001349  \n",
      "Epoch: [2][220/366] Elapsed 5m 46s (remain 3m 47s) Loss: 0.2448(0.2251) Grad: 86392.8984  LR: 0.00001309  \n",
      "Epoch: [2][240/366] Elapsed 6m 15s (remain 3m 14s) Loss: 0.1576(0.2218) Grad: 61888.9141  LR: 0.00001268  \n",
      "Epoch: [2][260/366] Elapsed 6m 52s (remain 2m 45s) Loss: 0.1714(0.2204) Grad: 34422.2734  LR: 0.00001226  \n",
      "Epoch: [2][280/366] Elapsed 7m 24s (remain 2m 14s) Loss: 0.2449(0.2167) Grad: 43935.9766  LR: 0.00001184  \n",
      "Epoch: [2][300/366] Elapsed 7m 54s (remain 1m 42s) Loss: 0.1591(0.2131) Grad: 35606.9688  LR: 0.00001142  \n",
      "Epoch: [2][320/366] Elapsed 8m 25s (remain 1m 10s) Loss: 0.2657(0.2106) Grad: 125164.6797  LR: 0.00001099  \n",
      "Epoch: [2][340/366] Elapsed 8m 55s (remain 0m 39s) Loss: 0.1297(0.2079) Grad: 56656.7969  LR: 0.00001057  \n",
      "Epoch: [2][360/366] Elapsed 9m 25s (remain 0m 7s) Loss: 0.1486(0.2060) Grad: 32428.8457  LR: 0.00001014  \n",
      "Epoch: [2][365/366] Elapsed 9m 34s (remain 0m 0s) Loss: 0.2756(0.2058) Grad: 67114.0391  LR: 0.00001003  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 41s) Loss: 0.1602(0.1602) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 17s) Loss: 0.2418(0.2402) \n",
      "EVAL: [40/123] Elapsed 0m 23s (remain 0m 47s) Loss: 0.2690(0.2307) \n",
      "EVAL: [60/123] Elapsed 0m 29s (remain 0m 29s) Loss: 0.1993(0.2276) \n",
      "EVAL: [80/123] Elapsed 0m 33s (remain 0m 17s) Loss: 0.1747(0.2173) \n",
      "EVAL: [100/123] Elapsed 0m 37s (remain 0m 8s) Loss: 0.1499(0.2148) \n",
      "EVAL: [120/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.1609(0.2130) \n",
      "EVAL: [122/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.0683(0.2127) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2058  avg_val_loss: 0.2127  time: 614s\n",
      "Epoch 2 - Score: 0.4607\n",
      "Epoch 2 - Save Best Score: 0.4607 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [3][0/366] Elapsed 0m 1s (remain 8m 4s) Loss: 0.1307(0.1307) Grad: 206219.1719  LR: 0.00001001  \n",
      "Epoch: [3][20/366] Elapsed 0m 34s (remain 9m 21s) Loss: 0.1491(0.1677) Grad: 246500.3125  LR: 0.00000958  \n",
      "Epoch: [3][40/366] Elapsed 1m 2s (remain 8m 17s) Loss: 0.0985(0.1677) Grad: 293871.1250  LR: 0.00000916  \n",
      "Epoch: [3][60/366] Elapsed 1m 29s (remain 7m 27s) Loss: 0.1596(0.1639) Grad: 195270.2656  LR: 0.00000873  \n",
      "Epoch: [3][80/366] Elapsed 2m 3s (remain 7m 14s) Loss: 0.2206(0.1624) Grad: 355493.5312  LR: 0.00000831  \n",
      "Epoch: [3][100/366] Elapsed 2m 32s (remain 6m 39s) Loss: 0.1755(0.1618) Grad: 312810.0312  LR: 0.00000789  \n",
      "Epoch: [3][120/366] Elapsed 3m 0s (remain 6m 5s) Loss: 0.1146(0.1610) Grad: 303684.4688  LR: 0.00000747  \n",
      "Epoch: [3][140/366] Elapsed 3m 32s (remain 5m 39s) Loss: 0.2168(0.1616) Grad: 152571.2969  LR: 0.00000706  \n",
      "Epoch: [3][160/366] Elapsed 4m 0s (remain 5m 6s) Loss: 0.1974(0.1634) Grad: 393570.9375  LR: 0.00000665  \n",
      "Epoch: [3][180/366] Elapsed 4m 34s (remain 4m 40s) Loss: 0.1355(0.1633) Grad: 343014.6562  LR: 0.00000625  \n",
      "Epoch: [3][200/366] Elapsed 5m 2s (remain 4m 8s) Loss: 0.1387(0.1630) Grad: 242738.1562  LR: 0.00000586  \n",
      "Epoch: [3][220/366] Elapsed 5m 43s (remain 3m 45s) Loss: 0.1834(0.1636) Grad: 354393.6875  LR: 0.00000547  \n",
      "Epoch: [3][240/366] Elapsed 6m 12s (remain 3m 13s) Loss: 0.1561(0.1629) Grad: 155513.8906  LR: 0.00000509  \n",
      "Epoch: [3][260/366] Elapsed 6m 43s (remain 2m 42s) Loss: 0.2069(0.1625) Grad: 233895.9375  LR: 0.00000472  \n",
      "Epoch: [3][280/366] Elapsed 7m 16s (remain 2m 12s) Loss: 0.1202(0.1632) Grad: 251943.6094  LR: 0.00000437  \n",
      "Epoch: [3][300/366] Elapsed 7m 52s (remain 1m 42s) Loss: 0.1009(0.1631) Grad: 244575.7188  LR: 0.00000402  \n",
      "Epoch: [3][320/366] Elapsed 8m 25s (remain 1m 10s) Loss: 0.1894(0.1630) Grad: 243874.1094  LR: 0.00000368  \n",
      "Epoch: [3][340/366] Elapsed 8m 59s (remain 0m 39s) Loss: 0.1967(0.1624) Grad: 274811.0938  LR: 0.00000335  \n",
      "Epoch: [3][360/366] Elapsed 9m 36s (remain 0m 7s) Loss: 0.2066(0.1627) Grad: 285762.4375  LR: 0.00000304  \n",
      "Epoch: [3][365/366] Elapsed 9m 43s (remain 0m 0s) Loss: 0.1027(0.1622) Grad: 213063.2812  LR: 0.00000296  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 43s) Loss: 0.1626(0.1626) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 17s) Loss: 0.2386(0.2320) \n",
      "EVAL: [40/123] Elapsed 0m 23s (remain 0m 47s) Loss: 0.2713(0.2234) \n",
      "EVAL: [60/123] Elapsed 0m 29s (remain 0m 29s) Loss: 0.2048(0.2226) \n",
      "EVAL: [80/123] Elapsed 0m 33s (remain 0m 17s) Loss: 0.1728(0.2138) \n",
      "EVAL: [100/123] Elapsed 0m 37s (remain 0m 8s) Loss: 0.1393(0.2112) \n",
      "EVAL: [120/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.1617(0.2096) \n",
      "EVAL: [122/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.0681(0.2093) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1622  avg_val_loss: 0.2093  time: 624s\n",
      "Epoch 3 - Score: 0.4570\n",
      "Epoch 3 - Save Best Score: 0.4570 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [4][0/366] Elapsed 0m 1s (remain 9m 5s) Loss: 0.1662(0.1662) Grad: 146601.1250  LR: 0.00000295  \n",
      "Epoch: [4][20/366] Elapsed 0m 37s (remain 10m 14s) Loss: 0.1655(0.1753) Grad: 427446.6250  LR: 0.00000265  \n",
      "Epoch: [4][40/366] Elapsed 1m 11s (remain 9m 29s) Loss: 0.2509(0.1758) Grad: 521125.7500  LR: 0.00000237  \n",
      "Epoch: [4][60/366] Elapsed 1m 40s (remain 8m 22s) Loss: 0.2006(0.1706) Grad: 209899.8906  LR: 0.00000210  \n",
      "Epoch: [4][80/366] Elapsed 2m 6s (remain 7m 26s) Loss: 0.1392(0.1674) Grad: 304259.7812  LR: 0.00000184  \n",
      "Epoch: [4][100/366] Elapsed 2m 41s (remain 7m 4s) Loss: 0.1575(0.1662) Grad: 257898.7500  LR: 0.00000160  \n",
      "Epoch: [4][120/366] Elapsed 3m 17s (remain 6m 40s) Loss: 0.1577(0.1635) Grad: 141300.0938  LR: 0.00000138  \n",
      "Epoch: [4][140/366] Elapsed 3m 44s (remain 5m 58s) Loss: 0.1678(0.1612) Grad: 143492.6875  LR: 0.00000117  \n",
      "Epoch: [4][160/366] Elapsed 4m 16s (remain 5m 27s) Loss: 0.1336(0.1607) Grad: 190251.6250  LR: 0.00000098  \n",
      "Epoch: [4][180/366] Elapsed 4m 49s (remain 4m 55s) Loss: 0.1727(0.1609) Grad: 247861.1250  LR: 0.00000080  \n",
      "Epoch: [4][200/366] Elapsed 5m 19s (remain 4m 22s) Loss: 0.2095(0.1618) Grad: 365601.8750  LR: 0.00000064  \n",
      "Epoch: [4][220/366] Elapsed 5m 48s (remain 3m 48s) Loss: 0.1470(0.1612) Grad: 185648.7500  LR: 0.00000050  \n",
      "Epoch: [4][240/366] Elapsed 6m 21s (remain 3m 18s) Loss: 0.1372(0.1595) Grad: 316528.0312  LR: 0.00000037  \n",
      "Epoch: [4][260/366] Elapsed 7m 1s (remain 2m 49s) Loss: 0.1256(0.1594) Grad: 313036.7188  LR: 0.00000027  \n",
      "Epoch: [4][280/366] Elapsed 7m 36s (remain 2m 18s) Loss: 0.1871(0.1593) Grad: 233393.8750  LR: 0.00000018  \n",
      "Epoch: [4][300/366] Elapsed 8m 10s (remain 1m 45s) Loss: 0.1507(0.1599) Grad: 209086.3906  LR: 0.00000011  \n",
      "Epoch: [4][320/366] Elapsed 8m 33s (remain 1m 12s) Loss: 0.1410(0.1594) Grad: 245863.0156  LR: 0.00000005  \n",
      "Epoch: [4][340/366] Elapsed 9m 5s (remain 0m 39s) Loss: 0.1753(0.1597) Grad: 189243.9844  LR: 0.00000002  \n",
      "Epoch: [4][360/366] Elapsed 9m 35s (remain 0m 7s) Loss: 0.1028(0.1592) Grad: 196142.4062  LR: 0.00000000  \n",
      "Epoch: [4][365/366] Elapsed 9m 42s (remain 0m 0s) Loss: 0.1205(0.1589) Grad: 255884.9219  LR: 0.00000000  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 41s) Loss: 0.1618(0.1618) \n",
      "EVAL: [20/123] Elapsed 0m 15s (remain 1m 17s) Loss: 0.2394(0.2326) \n",
      "EVAL: [40/123] Elapsed 0m 23s (remain 0m 47s) Loss: 0.2712(0.2239) \n",
      "EVAL: [60/123] Elapsed 0m 29s (remain 0m 30s) Loss: 0.2038(0.2228) \n",
      "EVAL: [80/123] Elapsed 0m 34s (remain 0m 17s) Loss: 0.1722(0.2137) \n",
      "EVAL: [100/123] Elapsed 0m 37s (remain 0m 8s) Loss: 0.1414(0.2111) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1589  avg_val_loss: 0.2093  time: 622s\n",
      "Epoch 4 - Score: 0.4570\n",
      "Epoch 4 - Save Best Score: 0.4570 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.1609(0.2096) \n",
      "EVAL: [122/123] Elapsed 0m 39s (remain 0m 0s) Loss: 0.0665(0.2093) \n",
      "AWP is triggered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.4570\n",
      "========== fold: 2 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [1][0/366] Elapsed 0m 3s (remain 23m 4s) Loss: 11.5938(11.5938) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/366] Elapsed 0m 38s (remain 10m 36s) Loss: 0.3239(4.4519) Grad: 33579.7969  LR: 0.00001999  \n",
      "Epoch: [1][40/366] Elapsed 1m 13s (remain 9m 46s) Loss: 0.2188(2.4553) Grad: 13181.6260  LR: 0.00001996  \n",
      "Epoch: [1][60/366] Elapsed 1m 40s (remain 8m 24s) Loss: 0.2323(1.7407) Grad: 18630.3418  LR: 0.00001991  \n",
      "Epoch: [1][80/366] Elapsed 2m 15s (remain 7m 55s) Loss: 0.1831(1.3858) Grad: 12471.2822  LR: 0.00001985  \n",
      "Epoch: [1][100/366] Elapsed 2m 46s (remain 7m 17s) Loss: 0.2596(1.1708) Grad: 20136.3047  LR: 0.00001977  \n",
      "Epoch: [1][120/366] Elapsed 3m 17s (remain 6m 39s) Loss: 0.2356(1.0281) Grad: 15845.3711  LR: 0.00001967  \n",
      "Epoch: [1][140/366] Elapsed 3m 50s (remain 6m 7s) Loss: 0.2624(0.9162) Grad: 14499.8428  LR: 0.00001955  \n",
      "Epoch: [1][160/366] Elapsed 4m 22s (remain 5m 34s) Loss: 0.1589(0.8336) Grad: 5874.4277  LR: 0.00001941  \n",
      "Epoch: [1][180/366] Elapsed 4m 52s (remain 4m 58s) Loss: 0.4155(0.7703) Grad: 24670.8984  LR: 0.00001926  \n",
      "Epoch: [1][200/366] Elapsed 5m 28s (remain 4m 29s) Loss: 0.2753(0.7208) Grad: 12500.1533  LR: 0.00001909  \n",
      "Epoch: [1][220/366] Elapsed 6m 4s (remain 3m 59s) Loss: 0.3016(0.6784) Grad: 22883.2832  LR: 0.00001890  \n",
      "Epoch: [1][240/366] Elapsed 6m 30s (remain 3m 22s) Loss: 0.3538(0.6454) Grad: 24327.4414  LR: 0.00001870  \n",
      "Epoch: [1][260/366] Elapsed 6m 58s (remain 2m 48s) Loss: 0.2408(0.6125) Grad: 17382.2109  LR: 0.00001848  \n",
      "Epoch: [1][280/366] Elapsed 7m 34s (remain 2m 17s) Loss: 0.1792(0.5843) Grad: 14106.4658  LR: 0.00001824  \n",
      "Epoch: [1][300/366] Elapsed 8m 9s (remain 1m 45s) Loss: 0.1597(0.5602) Grad: 7016.5488  LR: 0.00001799  \n",
      "Epoch: [1][320/366] Elapsed 8m 44s (remain 1m 13s) Loss: 0.2959(0.5413) Grad: 17564.8809  LR: 0.00001773  \n",
      "Epoch: [1][340/366] Elapsed 9m 10s (remain 0m 40s) Loss: 0.2163(0.5250) Grad: 5026.1816  LR: 0.00001745  \n",
      "Epoch: [1][360/366] Elapsed 9m 44s (remain 0m 8s) Loss: 0.2088(0.5078) Grad: 8452.8682  LR: 0.00001715  \n",
      "Epoch: [1][365/366] Elapsed 9m 54s (remain 0m 0s) Loss: 0.2704(0.5045) Grad: 13783.2588  LR: 0.00001708  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 30s) Loss: 0.3195(0.3195) \n",
      "EVAL: [20/123] Elapsed 0m 13s (remain 1m 5s) Loss: 0.3304(0.2881) \n",
      "EVAL: [40/123] Elapsed 0m 20s (remain 0m 40s) Loss: 0.1236(0.2625) \n",
      "EVAL: [60/123] Elapsed 0m 25s (remain 0m 26s) Loss: 0.1603(0.2528) \n",
      "EVAL: [80/123] Elapsed 0m 29s (remain 0m 15s) Loss: 0.1697(0.2424) \n",
      "EVAL: [100/123] Elapsed 0m 33s (remain 0m 7s) Loss: 0.1484(0.2383) \n",
      "EVAL: [120/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.2212(0.2352) \n",
      "EVAL: [122/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.3301(0.2353) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5045  avg_val_loss: 0.2353  time: 630s\n",
      "Epoch 1 - Score: 0.4830\n",
      "Epoch 1 - Save Best Score: 0.4830 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [2][0/366] Elapsed 0m 3s (remain 18m 22s) Loss: 0.1763(0.1763) Grad: inf  LR: 0.00001706  \n",
      "Epoch: [2][20/366] Elapsed 0m 28s (remain 7m 40s) Loss: 0.2141(0.2197) Grad: 215876.1406  LR: 0.00001675  \n",
      "Epoch: [2][40/366] Elapsed 0m 59s (remain 7m 50s) Loss: 0.1450(0.2293) Grad: 76828.1719  LR: 0.00001643  \n",
      "Epoch: [2][60/366] Elapsed 1m 32s (remain 7m 40s) Loss: 0.1351(0.2152) Grad: 170969.6250  LR: 0.00001610  \n",
      "Epoch: [2][80/366] Elapsed 2m 2s (remain 7m 12s) Loss: 0.1930(0.2101) Grad: 105015.6172  LR: 0.00001575  \n",
      "Epoch: [2][100/366] Elapsed 2m 37s (remain 6m 52s) Loss: 0.1581(0.2085) Grad: 117128.1484  LR: 0.00001540  \n",
      "Epoch: [2][120/366] Elapsed 3m 16s (remain 6m 38s) Loss: 0.1934(0.2034) Grad: 122346.3594  LR: 0.00001503  \n",
      "Epoch: [2][140/366] Elapsed 3m 56s (remain 6m 16s) Loss: 0.2304(0.2014) Grad: 192513.3906  LR: 0.00001466  \n",
      "Epoch: [2][160/366] Elapsed 4m 29s (remain 5m 42s) Loss: 0.1351(0.1984) Grad: 125888.0781  LR: 0.00001427  \n",
      "Epoch: [2][180/366] Elapsed 5m 3s (remain 5m 10s) Loss: 0.1825(0.1953) Grad: 156757.7969  LR: 0.00001388  \n",
      "Epoch: [2][200/366] Elapsed 5m 35s (remain 4m 35s) Loss: 0.1349(0.1917) Grad: 166070.9531  LR: 0.00001348  \n",
      "Epoch: [2][220/366] Elapsed 6m 3s (remain 3m 58s) Loss: 0.1631(0.1883) Grad: 65961.1328  LR: 0.00001308  \n",
      "Epoch: [2][240/366] Elapsed 6m 40s (remain 3m 27s) Loss: 0.1015(0.1869) Grad: 146652.2500  LR: 0.00001267  \n",
      "Epoch: [2][260/366] Elapsed 7m 15s (remain 2m 55s) Loss: 0.1326(0.1851) Grad: 122442.9922  LR: 0.00001225  \n",
      "Epoch: [2][280/366] Elapsed 7m 54s (remain 2m 23s) Loss: 0.1635(0.1829) Grad: 92934.4141  LR: 0.00001183  \n",
      "Epoch: [2][300/366] Elapsed 8m 28s (remain 1m 49s) Loss: 0.1586(0.1823) Grad: 83935.4922  LR: 0.00001141  \n",
      "Epoch: [2][320/366] Elapsed 9m 2s (remain 1m 16s) Loss: 0.2483(0.1823) Grad: 74849.5391  LR: 0.00001098  \n",
      "Epoch: [2][340/366] Elapsed 9m 33s (remain 0m 42s) Loss: 0.1635(0.1822) Grad: 132903.2344  LR: 0.00001056  \n",
      "Epoch: [2][360/366] Elapsed 10m 4s (remain 0m 8s) Loss: 0.1699(0.1817) Grad: 116834.0234  LR: 0.00001013  \n",
      "Epoch: [2][365/366] Elapsed 10m 11s (remain 0m 0s) Loss: 0.1007(0.1814) Grad: 128626.7500  LR: 0.00001002  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 33s) Loss: 0.3160(0.3160) \n",
      "EVAL: [20/123] Elapsed 0m 13s (remain 1m 5s) Loss: 0.3430(0.2668) \n",
      "EVAL: [40/123] Elapsed 0m 20s (remain 0m 40s) Loss: 0.1107(0.2459) \n",
      "EVAL: [60/123] Elapsed 0m 25s (remain 0m 25s) Loss: 0.1204(0.2313) \n",
      "EVAL: [80/123] Elapsed 0m 29s (remain 0m 15s) Loss: 0.1782(0.2216) \n",
      "EVAL: [100/123] Elapsed 0m 32s (remain 0m 7s) Loss: 0.1528(0.2165) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1814  avg_val_loss: 0.2114  time: 647s\n",
      "Epoch 2 - Score: 0.4593\n",
      "Epoch 2 - Save Best Score: 0.4593 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.1802(0.2119) \n",
      "EVAL: [122/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.2129(0.2114) \n",
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [3][0/366] Elapsed 0m 1s (remain 6m 12s) Loss: 0.0972(0.0972) Grad: 97288.8438  LR: 0.00001000  \n",
      "Epoch: [3][20/366] Elapsed 0m 32s (remain 8m 53s) Loss: 0.2046(0.1794) Grad: 208980.5469  LR: 0.00000957  \n",
      "Epoch: [3][40/366] Elapsed 1m 19s (remain 10m 30s) Loss: 0.2007(0.1746) Grad: 166157.7812  LR: 0.00000914  \n",
      "Epoch: [3][60/366] Elapsed 1m 52s (remain 9m 24s) Loss: 0.1646(0.1705) Grad: 102312.3359  LR: 0.00000872  \n",
      "Epoch: [3][80/366] Elapsed 2m 23s (remain 8m 25s) Loss: 0.1295(0.1679) Grad: 74229.7578  LR: 0.00000829  \n",
      "Epoch: [3][100/366] Elapsed 2m 53s (remain 7m 35s) Loss: 0.1689(0.1655) Grad: 151763.2500  LR: 0.00000787  \n",
      "Epoch: [3][120/366] Elapsed 3m 27s (remain 7m 0s) Loss: 0.1280(0.1670) Grad: 131152.7188  LR: 0.00000746  \n",
      "Epoch: [3][140/366] Elapsed 3m 59s (remain 6m 22s) Loss: 0.1527(0.1673) Grad: 128644.9062  LR: 0.00000704  \n",
      "Epoch: [3][160/366] Elapsed 4m 27s (remain 5m 41s) Loss: 0.1287(0.1695) Grad: 108322.0938  LR: 0.00000664  \n",
      "Epoch: [3][180/366] Elapsed 5m 3s (remain 5m 10s) Loss: 0.1210(0.1692) Grad: 114226.4922  LR: 0.00000624  \n",
      "Epoch: [3][200/366] Elapsed 5m 38s (remain 4m 37s) Loss: 0.1033(0.1683) Grad: 127500.4219  LR: 0.00000584  \n",
      "Epoch: [3][220/366] Elapsed 6m 12s (remain 4m 4s) Loss: 0.0890(0.1673) Grad: 82288.2500  LR: 0.00000546  \n",
      "Epoch: [3][240/366] Elapsed 6m 43s (remain 3m 29s) Loss: 0.1687(0.1673) Grad: 126592.4844  LR: 0.00000508  \n",
      "Epoch: [3][260/366] Elapsed 7m 13s (remain 2m 54s) Loss: 0.2125(0.1672) Grad: 147311.2344  LR: 0.00000471  \n",
      "Epoch: [3][280/366] Elapsed 7m 51s (remain 2m 22s) Loss: 0.1789(0.1672) Grad: 111614.3281  LR: 0.00000435  \n",
      "Epoch: [3][300/366] Elapsed 8m 19s (remain 1m 47s) Loss: 0.1465(0.1658) Grad: 127846.5156  LR: 0.00000400  \n",
      "Epoch: [3][320/366] Elapsed 8m 53s (remain 1m 14s) Loss: 0.1083(0.1652) Grad: 88023.1250  LR: 0.00000367  \n",
      "Epoch: [3][340/366] Elapsed 9m 30s (remain 0m 41s) Loss: 0.1346(0.1646) Grad: 113853.9375  LR: 0.00000334  \n",
      "Epoch: [3][360/366] Elapsed 10m 1s (remain 0m 8s) Loss: 0.1558(0.1647) Grad: 206096.8438  LR: 0.00000303  \n",
      "Epoch: [3][365/366] Elapsed 10m 8s (remain 0m 0s) Loss: 0.2555(0.1649) Grad: 120733.3828  LR: 0.00000295  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 31s) Loss: 0.2900(0.2900) \n",
      "EVAL: [20/123] Elapsed 0m 13s (remain 1m 5s) Loss: 0.3451(0.2645) \n",
      "EVAL: [40/123] Elapsed 0m 20s (remain 0m 40s) Loss: 0.1162(0.2431) \n",
      "EVAL: [60/123] Elapsed 0m 25s (remain 0m 26s) Loss: 0.1243(0.2295) \n",
      "EVAL: [80/123] Elapsed 0m 29s (remain 0m 15s) Loss: 0.1796(0.2199) \n",
      "EVAL: [100/123] Elapsed 0m 33s (remain 0m 7s) Loss: 0.1470(0.2155) \n",
      "EVAL: [120/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.1729(0.2109) \n",
      "EVAL: [122/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.2277(0.2105) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1649  avg_val_loss: 0.2105  time: 644s\n",
      "Epoch 3 - Score: 0.4583\n",
      "Epoch 3 - Save Best Score: 0.4583 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [4][0/366] Elapsed 0m 2s (remain 17m 40s) Loss: 0.1028(0.1028) Grad: 223372.4375  LR: 0.00000294  \n",
      "Epoch: [4][20/366] Elapsed 0m 32s (remain 8m 50s) Loss: 0.2391(0.1576) Grad: 123817.1875  LR: 0.00000264  \n",
      "Epoch: [4][40/366] Elapsed 1m 10s (remain 9m 14s) Loss: 0.2537(0.1643) Grad: 188106.3750  LR: 0.00000236  \n",
      "Epoch: [4][60/366] Elapsed 1m 37s (remain 8m 5s) Loss: 0.1576(0.1598) Grad: 92109.0000  LR: 0.00000209  \n",
      "Epoch: [4][80/366] Elapsed 2m 9s (remain 7m 35s) Loss: 0.1782(0.1590) Grad: 70676.6797  LR: 0.00000183  \n",
      "Epoch: [4][100/366] Elapsed 2m 44s (remain 7m 12s) Loss: 0.1719(0.1589) Grad: 109109.9453  LR: 0.00000159  \n",
      "Epoch: [4][120/366] Elapsed 3m 14s (remain 6m 33s) Loss: 0.1575(0.1592) Grad: 128107.7969  LR: 0.00000137  \n",
      "Epoch: [4][140/366] Elapsed 3m 43s (remain 5m 57s) Loss: 0.1955(0.1618) Grad: 151486.4844  LR: 0.00000116  \n",
      "Epoch: [4][160/366] Elapsed 4m 21s (remain 5m 33s) Loss: 0.2508(0.1594) Grad: 172366.8594  LR: 0.00000097  \n",
      "Epoch: [4][180/366] Elapsed 4m 58s (remain 5m 4s) Loss: 0.1311(0.1606) Grad: 146212.3906  LR: 0.00000079  \n",
      "Epoch: [4][200/366] Elapsed 5m 32s (remain 4m 32s) Loss: 0.0906(0.1598) Grad: 81215.8125  LR: 0.00000063  \n",
      "Epoch: [4][220/366] Elapsed 6m 4s (remain 3m 59s) Loss: 0.1390(0.1609) Grad: 102632.5625  LR: 0.00000049  \n",
      "Epoch: [4][240/366] Elapsed 6m 34s (remain 3m 24s) Loss: 0.1198(0.1596) Grad: 99689.1797  LR: 0.00000037  \n",
      "Epoch: [4][260/366] Elapsed 7m 5s (remain 2m 51s) Loss: 0.1215(0.1594) Grad: 122691.3672  LR: 0.00000026  \n",
      "Epoch: [4][280/366] Elapsed 7m 40s (remain 2m 19s) Loss: 0.1492(0.1593) Grad: 142518.9844  LR: 0.00000017  \n",
      "Epoch: [4][300/366] Elapsed 8m 18s (remain 1m 47s) Loss: 0.2310(0.1593) Grad: 106868.3906  LR: 0.00000010  \n",
      "Epoch: [4][320/366] Elapsed 8m 54s (remain 1m 14s) Loss: 0.1109(0.1599) Grad: 110066.9453  LR: 0.00000005  \n",
      "Epoch: [4][340/366] Elapsed 9m 29s (remain 0m 41s) Loss: 0.1040(0.1597) Grad: 113410.5078  LR: 0.00000002  \n",
      "Epoch: [4][360/366] Elapsed 10m 8s (remain 0m 8s) Loss: 0.2165(0.1599) Grad: 130810.2656  LR: 0.00000000  \n",
      "Epoch: [4][365/366] Elapsed 10m 17s (remain 0m 0s) Loss: 0.2287(0.1600) Grad: 106652.5391  LR: 0.00000000  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 31s) Loss: 0.3097(0.3097) \n",
      "EVAL: [20/123] Elapsed 0m 13s (remain 1m 5s) Loss: 0.3535(0.2668) \n",
      "EVAL: [40/123] Elapsed 0m 20s (remain 0m 40s) Loss: 0.1097(0.2457) \n",
      "EVAL: [60/123] Elapsed 0m 25s (remain 0m 26s) Loss: 0.1195(0.2304) \n",
      "EVAL: [80/123] Elapsed 0m 29s (remain 0m 15s) Loss: 0.1831(0.2207) \n",
      "EVAL: [100/123] Elapsed 0m 33s (remain 0m 7s) Loss: 0.1526(0.2156) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1600  avg_val_loss: 0.2103  time: 653s\n",
      "Epoch 4 - Score: 0.4580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.1737(0.2108) \n",
      "EVAL: [122/123] Elapsed 0m 35s (remain 0m 0s) Loss: 0.2109(0.2103) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Save Best Score: 0.4580 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 0.4580\n",
      "========== fold: 3 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable AWP\n",
      "Epoch: [1][0/366] Elapsed 0m 3s (remain 22m 35s) Loss: 8.8419(8.8419) Grad: inf  LR: 0.00002000  \n",
      "Epoch: [1][20/366] Elapsed 0m 35s (remain 9m 35s) Loss: 0.2286(3.9141) Grad: 26703.4004  LR: 0.00001999  \n",
      "Epoch: [1][40/366] Elapsed 1m 10s (remain 9m 20s) Loss: 0.1576(2.1755) Grad: 7054.7559  LR: 0.00001996  \n",
      "Epoch: [1][60/366] Elapsed 1m 43s (remain 8m 38s) Loss: 0.4279(1.5663) Grad: 52172.2031  LR: 0.00001991  \n",
      "Epoch: [1][80/366] Elapsed 2m 14s (remain 7m 53s) Loss: 0.1895(1.2469) Grad: 11553.2871  LR: 0.00001985  \n",
      "Epoch: [1][100/366] Elapsed 2m 46s (remain 7m 16s) Loss: 0.2907(1.0531) Grad: 12816.2930  LR: 0.00001977  \n",
      "Epoch: [1][120/366] Elapsed 3m 14s (remain 6m 34s) Loss: 0.3526(0.9249) Grad: 30344.4863  LR: 0.00001967  \n",
      "Epoch: [1][140/366] Elapsed 3m 49s (remain 6m 6s) Loss: 0.3493(0.8335) Grad: 12617.8496  LR: 0.00001955  \n",
      "Epoch: [1][160/366] Elapsed 4m 25s (remain 5m 37s) Loss: 0.4963(0.7638) Grad: 24967.9082  LR: 0.00001941  \n",
      "Epoch: [1][180/366] Elapsed 4m 55s (remain 5m 2s) Loss: 0.2267(0.7061) Grad: 15723.4648  LR: 0.00001926  \n",
      "Epoch: [1][200/366] Elapsed 5m 29s (remain 4m 30s) Loss: 0.2429(0.6603) Grad: 5360.0200  LR: 0.00001909  \n",
      "Epoch: [1][220/366] Elapsed 5m 57s (remain 3m 54s) Loss: 0.1790(0.6227) Grad: 10498.8633  LR: 0.00001890  \n",
      "Epoch: [1][240/366] Elapsed 6m 32s (remain 3m 23s) Loss: 0.1917(0.5914) Grad: 7448.2407  LR: 0.00001870  \n",
      "Epoch: [1][260/366] Elapsed 7m 3s (remain 2m 50s) Loss: 0.1891(0.5635) Grad: 12884.8037  LR: 0.00001848  \n",
      "Epoch: [1][280/366] Elapsed 7m 40s (remain 2m 19s) Loss: 0.2165(0.5405) Grad: 20496.8516  LR: 0.00001824  \n",
      "Epoch: [1][300/366] Elapsed 8m 9s (remain 1m 45s) Loss: 0.1910(0.5219) Grad: 8332.9404  LR: 0.00001799  \n",
      "Epoch: [1][320/366] Elapsed 8m 46s (remain 1m 13s) Loss: 0.2053(0.5043) Grad: 8757.9248  LR: 0.00001773  \n",
      "Epoch: [1][340/366] Elapsed 9m 19s (remain 0m 40s) Loss: 0.3403(0.4892) Grad: 23043.2812  LR: 0.00001745  \n",
      "Epoch: [1][360/366] Elapsed 9m 50s (remain 0m 8s) Loss: 0.2701(0.4759) Grad: 8582.1992  LR: 0.00001715  \n",
      "Epoch: [1][365/366] Elapsed 10m 1s (remain 0m 0s) Loss: 0.1489(0.4720) Grad: 12309.7236  LR: 0.00001708  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 28s) Loss: 0.3091(0.3091) \n",
      "EVAL: [20/123] Elapsed 0m 14s (remain 1m 8s) Loss: 0.2019(0.2291) \n",
      "EVAL: [40/123] Elapsed 0m 21s (remain 0m 43s) Loss: 0.2369(0.2215) \n",
      "EVAL: [60/123] Elapsed 0m 27s (remain 0m 27s) Loss: 0.1559(0.2275) \n",
      "EVAL: [80/123] Elapsed 0m 31s (remain 0m 16s) Loss: 0.1996(0.2270) \n",
      "EVAL: [100/123] Elapsed 0m 34s (remain 0m 7s) Loss: 0.1788(0.2201) \n",
      "EVAL: [120/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2515(0.2161) \n",
      "EVAL: [122/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.1918(0.2160) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4720  avg_val_loss: 0.2160  time: 638s\n",
      "Epoch 1 - Score: 0.4631\n",
      "Epoch 1 - Save Best Score: 0.4631 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [2][0/366] Elapsed 0m 2s (remain 12m 35s) Loss: 0.2178(0.2178) Grad: inf  LR: 0.00001706  \n",
      "Epoch: [2][20/366] Elapsed 0m 30s (remain 8m 13s) Loss: 0.2148(0.2149) Grad: 81734.5625  LR: 0.00001675  \n",
      "Epoch: [2][40/366] Elapsed 1m 4s (remain 8m 30s) Loss: 0.1711(0.1984) Grad: 69487.4219  LR: 0.00001643  \n",
      "Epoch: [2][60/366] Elapsed 1m 38s (remain 8m 12s) Loss: 0.1993(0.2013) Grad: 63750.7812  LR: 0.00001610  \n",
      "Epoch: [2][80/366] Elapsed 2m 9s (remain 7m 36s) Loss: 0.1366(0.1968) Grad: 35677.8828  LR: 0.00001575  \n",
      "Epoch: [2][100/366] Elapsed 2m 43s (remain 7m 8s) Loss: 0.1593(0.1910) Grad: 94860.2109  LR: 0.00001540  \n",
      "Epoch: [2][120/366] Elapsed 3m 16s (remain 6m 37s) Loss: 0.1302(0.1869) Grad: 76105.6797  LR: 0.00001503  \n",
      "Epoch: [2][140/366] Elapsed 3m 49s (remain 6m 6s) Loss: 0.1137(0.1855) Grad: 48438.3750  LR: 0.00001466  \n",
      "Epoch: [2][160/366] Elapsed 4m 23s (remain 5m 35s) Loss: 0.2726(0.1827) Grad: 59456.0469  LR: 0.00001427  \n",
      "Epoch: [2][180/366] Elapsed 4m 55s (remain 5m 1s) Loss: 0.1735(0.1814) Grad: 73968.7812  LR: 0.00001388  \n",
      "Epoch: [2][200/366] Elapsed 5m 20s (remain 4m 23s) Loss: 0.1797(0.1800) Grad: 39380.0273  LR: 0.00001348  \n",
      "Epoch: [2][220/366] Elapsed 5m 53s (remain 3m 51s) Loss: 0.1653(0.1820) Grad: 53983.6172  LR: 0.00001308  \n",
      "Epoch: [2][240/366] Elapsed 6m 27s (remain 3m 21s) Loss: 0.2479(0.1836) Grad: 84298.9297  LR: 0.00001267  \n",
      "Epoch: [2][260/366] Elapsed 6m 59s (remain 2m 48s) Loss: 0.1726(0.1828) Grad: 77579.4688  LR: 0.00001225  \n",
      "Epoch: [2][280/366] Elapsed 7m 34s (remain 2m 17s) Loss: 0.1832(0.1823) Grad: 64203.3359  LR: 0.00001183  \n",
      "Epoch: [2][300/366] Elapsed 8m 5s (remain 1m 44s) Loss: 0.1122(0.1814) Grad: 47262.6875  LR: 0.00001141  \n",
      "Epoch: [2][320/366] Elapsed 8m 39s (remain 1m 12s) Loss: 0.1826(0.1806) Grad: 84700.1484  LR: 0.00001098  \n",
      "Epoch: [2][340/366] Elapsed 9m 14s (remain 0m 40s) Loss: 0.1627(0.1798) Grad: 60073.1367  LR: 0.00001056  \n",
      "Epoch: [2][360/366] Elapsed 9m 51s (remain 0m 8s) Loss: 0.1645(0.1788) Grad: 72660.3438  LR: 0.00001013  \n",
      "Epoch: [2][365/366] Elapsed 10m 0s (remain 0m 0s) Loss: 0.2324(0.1789) Grad: 64979.0586  LR: 0.00001002  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 24s) Loss: 0.2826(0.2826) \n",
      "EVAL: [20/123] Elapsed 0m 14s (remain 1m 8s) Loss: 0.2169(0.2189) \n",
      "EVAL: [40/123] Elapsed 0m 21s (remain 0m 42s) Loss: 0.2105(0.2083) \n",
      "EVAL: [60/123] Elapsed 0m 27s (remain 0m 27s) Loss: 0.1353(0.2126) \n",
      "EVAL: [80/123] Elapsed 0m 31s (remain 0m 16s) Loss: 0.1918(0.2108) \n",
      "EVAL: [100/123] Elapsed 0m 34s (remain 0m 7s) Loss: 0.1559(0.2041) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1789  avg_val_loss: 0.1991  time: 637s\n",
      "Epoch 2 - Score: 0.4456\n",
      "Epoch 2 - Save Best Score: 0.4456 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [120/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2054(0.1991) \n",
      "EVAL: [122/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.1387(0.1991) \n",
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [3][0/366] Elapsed 0m 2s (remain 14m 54s) Loss: 0.2074(0.2074) Grad: 247478.1562  LR: 0.00001000  \n",
      "Epoch: [3][20/366] Elapsed 0m 36s (remain 10m 2s) Loss: 0.1894(0.1559) Grad: 152557.1094  LR: 0.00000957  \n",
      "Epoch: [3][40/366] Elapsed 1m 6s (remain 8m 43s) Loss: 0.0988(0.1539) Grad: 108554.8750  LR: 0.00000914  \n",
      "Epoch: [3][60/366] Elapsed 1m 41s (remain 8m 28s) Loss: 0.1781(0.1573) Grad: 169596.1094  LR: 0.00000872  \n",
      "Epoch: [3][80/366] Elapsed 2m 11s (remain 7m 41s) Loss: 0.1781(0.1582) Grad: 194284.6719  LR: 0.00000829  \n",
      "Epoch: [3][100/366] Elapsed 2m 42s (remain 7m 5s) Loss: 0.1547(0.1621) Grad: 157015.0469  LR: 0.00000787  \n",
      "Epoch: [3][120/366] Elapsed 3m 15s (remain 6m 35s) Loss: 0.1401(0.1623) Grad: 77424.2656  LR: 0.00000746  \n",
      "Epoch: [3][140/366] Elapsed 3m 43s (remain 5m 56s) Loss: 0.1878(0.1625) Grad: 141799.1250  LR: 0.00000704  \n",
      "Epoch: [3][160/366] Elapsed 4m 13s (remain 5m 22s) Loss: 0.1544(0.1629) Grad: 156555.4219  LR: 0.00000664  \n",
      "Epoch: [3][180/366] Elapsed 4m 51s (remain 4m 57s) Loss: 0.1259(0.1606) Grad: 129572.1406  LR: 0.00000624  \n",
      "Epoch: [3][200/366] Elapsed 5m 30s (remain 4m 31s) Loss: 0.1074(0.1614) Grad: 61305.3242  LR: 0.00000584  \n",
      "Epoch: [3][220/366] Elapsed 6m 1s (remain 3m 57s) Loss: 0.1465(0.1604) Grad: 120680.0938  LR: 0.00000546  \n",
      "Epoch: [3][240/366] Elapsed 6m 40s (remain 3m 27s) Loss: 0.0885(0.1604) Grad: 96527.2734  LR: 0.00000508  \n",
      "Epoch: [3][260/366] Elapsed 7m 17s (remain 2m 55s) Loss: 0.1975(0.1600) Grad: 68294.7734  LR: 0.00000471  \n",
      "Epoch: [3][280/366] Elapsed 7m 56s (remain 2m 24s) Loss: 0.1185(0.1601) Grad: 138728.1562  LR: 0.00000435  \n",
      "Epoch: [3][300/366] Elapsed 8m 27s (remain 1m 49s) Loss: 0.0861(0.1593) Grad: 55460.5195  LR: 0.00000400  \n",
      "Epoch: [3][320/366] Elapsed 8m 56s (remain 1m 15s) Loss: 0.1912(0.1593) Grad: 168961.3438  LR: 0.00000367  \n",
      "Epoch: [3][340/366] Elapsed 9m 31s (remain 0m 41s) Loss: 0.1741(0.1593) Grad: 87825.7344  LR: 0.00000334  \n",
      "Epoch: [3][360/366] Elapsed 10m 2s (remain 0m 8s) Loss: 0.1707(0.1603) Grad: 222439.4219  LR: 0.00000303  \n",
      "Epoch: [3][365/366] Elapsed 10m 11s (remain 0m 0s) Loss: 0.1505(0.1600) Grad: 83897.9297  LR: 0.00000295  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 23s) Loss: 0.2812(0.2812) \n",
      "EVAL: [20/123] Elapsed 0m 14s (remain 1m 8s) Loss: 0.1946(0.2126) \n",
      "EVAL: [40/123] Elapsed 0m 21s (remain 0m 42s) Loss: 0.2087(0.2033) \n",
      "EVAL: [60/123] Elapsed 0m 27s (remain 0m 27s) Loss: 0.1483(0.2096) \n",
      "EVAL: [80/123] Elapsed 0m 31s (remain 0m 16s) Loss: 0.1747(0.2083) \n",
      "EVAL: [100/123] Elapsed 0m 34s (remain 0m 7s) Loss: 0.1624(0.2026) \n",
      "EVAL: [120/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2255(0.1987) \n",
      "EVAL: [122/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.1357(0.1985) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1600  avg_val_loss: 0.1985  time: 648s\n",
      "Epoch 3 - Score: 0.4449\n",
      "Epoch 3 - Save Best Score: 0.4449 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n",
      "Enable AWP\n",
      "Epoch: [4][0/366] Elapsed 0m 1s (remain 8m 56s) Loss: 0.1353(0.1353) Grad: 206138.5625  LR: 0.00000294  \n",
      "Epoch: [4][20/366] Elapsed 0m 35s (remain 9m 48s) Loss: 0.1631(0.1597) Grad: 129416.5781  LR: 0.00000264  \n",
      "Epoch: [4][40/366] Elapsed 1m 0s (remain 7m 58s) Loss: 0.1335(0.1578) Grad: 132715.2500  LR: 0.00000236  \n",
      "Epoch: [4][60/366] Elapsed 1m 37s (remain 8m 7s) Loss: 0.1828(0.1567) Grad: 98651.5547  LR: 0.00000209  \n",
      "Epoch: [4][80/366] Elapsed 2m 12s (remain 7m 45s) Loss: 0.1546(0.1544) Grad: 91023.1953  LR: 0.00000183  \n",
      "Epoch: [4][100/366] Elapsed 2m 47s (remain 7m 19s) Loss: 0.1715(0.1550) Grad: 143342.1719  LR: 0.00000159  \n",
      "Epoch: [4][120/366] Elapsed 3m 20s (remain 6m 46s) Loss: 0.0999(0.1549) Grad: 103660.1953  LR: 0.00000137  \n",
      "Epoch: [4][140/366] Elapsed 3m 54s (remain 6m 13s) Loss: 0.1915(0.1535) Grad: 146539.9688  LR: 0.00000116  \n",
      "Epoch: [4][160/366] Elapsed 4m 25s (remain 5m 38s) Loss: 0.2383(0.1537) Grad: 127553.3438  LR: 0.00000097  \n",
      "Epoch: [4][180/366] Elapsed 4m 56s (remain 5m 3s) Loss: 0.1204(0.1531) Grad: 74819.7422  LR: 0.00000079  \n",
      "Epoch: [4][200/366] Elapsed 5m 32s (remain 4m 32s) Loss: 0.1063(0.1538) Grad: 56712.1406  LR: 0.00000063  \n",
      "Epoch: [4][220/366] Elapsed 6m 3s (remain 3m 58s) Loss: 0.1955(0.1544) Grad: 76326.9531  LR: 0.00000049  \n",
      "Epoch: [4][240/366] Elapsed 6m 35s (remain 3m 25s) Loss: 0.2041(0.1542) Grad: 124733.5391  LR: 0.00000037  \n",
      "Epoch: [4][260/366] Elapsed 7m 10s (remain 2m 53s) Loss: 0.1878(0.1541) Grad: 156493.5000  LR: 0.00000026  \n",
      "Epoch: [4][280/366] Elapsed 7m 43s (remain 2m 20s) Loss: 0.1584(0.1547) Grad: 191045.0312  LR: 0.00000017  \n",
      "Epoch: [4][300/366] Elapsed 8m 19s (remain 1m 47s) Loss: 0.1604(0.1543) Grad: 122345.7812  LR: 0.00000010  \n",
      "Epoch: [4][320/366] Elapsed 8m 57s (remain 1m 15s) Loss: 0.1650(0.1549) Grad: 156402.2344  LR: 0.00000005  \n",
      "Epoch: [4][340/366] Elapsed 9m 26s (remain 0m 41s) Loss: 0.1569(0.1543) Grad: 89528.4219  LR: 0.00000002  \n",
      "Epoch: [4][360/366] Elapsed 10m 2s (remain 0m 8s) Loss: 0.1343(0.1536) Grad: 119726.7578  LR: 0.00000000  \n",
      "Epoch: [4][365/366] Elapsed 10m 8s (remain 0m 0s) Loss: 0.1528(0.1539) Grad: 162381.1562  LR: 0.00000000  \n",
      "EVAL: [0/123] Elapsed 0m 1s (remain 3m 22s) Loss: 0.2781(0.2781) \n",
      "EVAL: [20/123] Elapsed 0m 14s (remain 1m 8s) Loss: 0.1997(0.2131) \n",
      "EVAL: [40/123] Elapsed 0m 21s (remain 0m 43s) Loss: 0.2082(0.2038) \n",
      "EVAL: [60/123] Elapsed 0m 27s (remain 0m 27s) Loss: 0.1461(0.2099) \n",
      "EVAL: [80/123] Elapsed 0m 31s (remain 0m 16s) Loss: 0.1766(0.2086) \n",
      "EVAL: [100/123] Elapsed 0m 34s (remain 0m 7s) Loss: 0.1595(0.2029) \n",
      "EVAL: [120/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2222(0.1985) \n",
      "EVAL: [122/123] Elapsed 0m 36s (remain 0m 0s) Loss: 0.1369(0.1984) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1539  avg_val_loss: 0.1984  time: 645s\n",
      "Epoch 4 - Score: 0.4448\n",
      "Epoch 4 - Save Best Score: 0.4448 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWP is triggered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 0.4448\n",
      "========== CV ==========\n",
      "Score: 0.4526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>█▁▁▁</td></tr><tr><td>[fold0] avg_val_loss</td><td>█▂▁▁</td></tr><tr><td>[fold0] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold0] loss</td><td>█▃▆▅█▄▇▅▄▂▂▃▂▂▃▂▃▄▃▇▃▂▃▄▂▂▃▄▂▄▄▃▅▄▁▃▄▂▃▂</td></tr><tr><td>[fold0] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] score</td><td>█▂▁▁</td></tr><tr><td>[fold1] avg_train_loss</td><td>█▂▁▁</td></tr><tr><td>[fold1] avg_val_loss</td><td>█▃▁▁</td></tr><tr><td>[fold1] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold1] loss</td><td>▆▅▄▃▄▃▃▃▄▃█▂▂▃▂▃▂▂▂▂▁▂▃▄▂▂▂▂▂▂▃▂▁▂▂▂▃▃▂▄</td></tr><tr><td>[fold1] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] score</td><td>█▃▁▁</td></tr><tr><td>[fold2] avg_train_loss</td><td>█▁▁▁</td></tr><tr><td>[fold2] avg_val_loss</td><td>█▁▁▁</td></tr><tr><td>[fold2] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold2] loss</td><td>▅▅▅▅▃▃█▄▄▅▃▅▄▃▃▃▃▄▂▄▁▂▃▃▂▂▃▂▂▃▃▃▃▁▃▁▁▂▂▃</td></tr><tr><td>[fold2] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] score</td><td>█▁▁▁</td></tr><tr><td>[fold3] avg_train_loss</td><td>█▂▁▁</td></tr><tr><td>[fold3] avg_val_loss</td><td>█▁▁▁</td></tr><tr><td>[fold3] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold3] loss</td><td>█▄▃▃▆▄▄▁▄▃▄▂▁▂▂▂▃▂▂▁▂▂▁▂▂▁▁▂▁▂▂▂▁▁▁▁▁▂▂▁</td></tr><tr><td>[fold3] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold3] score</td><td>█▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>0.17166</td></tr><tr><td>[fold0] avg_val_loss</td><td>0.20339</td></tr><tr><td>[fold0] epoch</td><td>4</td></tr><tr><td>[fold0] loss</td><td>0.22404</td></tr><tr><td>[fold0] lr</td><td>0.0</td></tr><tr><td>[fold0] score</td><td>0.45025</td></tr><tr><td>[fold1] avg_train_loss</td><td>0.15889</td></tr><tr><td>[fold1] avg_val_loss</td><td>0.20928</td></tr><tr><td>[fold1] epoch</td><td>4</td></tr><tr><td>[fold1] loss</td><td>0.1205</td></tr><tr><td>[fold1] lr</td><td>0.0</td></tr><tr><td>[fold1] score</td><td>0.45697</td></tr><tr><td>[fold2] avg_train_loss</td><td>0.16</td></tr><tr><td>[fold2] avg_val_loss</td><td>0.21027</td></tr><tr><td>[fold2] epoch</td><td>4</td></tr><tr><td>[fold2] loss</td><td>0.22871</td></tr><tr><td>[fold2] lr</td><td>0.0</td></tr><tr><td>[fold2] score</td><td>0.45801</td></tr><tr><td>[fold3] avg_train_loss</td><td>0.15392</td></tr><tr><td>[fold3] avg_val_loss</td><td>0.19841</td></tr><tr><td>[fold3] epoch</td><td>4</td></tr><tr><td>[fold3] loss</td><td>0.15279</td></tr><tr><td>[fold3] lr</td><td>0.0</td></tr><tr><td>[fold3] score</td><td>0.4448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">microsoft/deberta-v3-large</strong>: <a href=\"https://wandb.ai/kaggle-clrp/feedback-public/runs/1g4x9cxv\" target=\"_blank\">https://wandb.ai/kaggle-clrp/feedback-public/runs/1g4x9cxv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220920_051236-1g4x9cxv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        true = oof_df[CFG.target_cols].values\n",
    "        preds = oof_df[[\"pred_\" + c for c in labels]].values\n",
    "        score = get_score(true, preds)[0]\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4973b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_pickle('oof_df.pkl').to_csv('oof_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74496d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30329.017674,
   "end_time": "2022-03-22T18:05:22.040486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-22T09:39:53.022812",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "126a1e5f24e44838a03204815209c5dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "12d0d3a78caf4f8c93da02229f2185df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14972cafd36646939e742a987e1d0ec7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "181ebde2d0064fb99b8ec32e9dc76836": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c1e8e53062324cf38fbd75eab01e066a",
       "placeholder": "​",
       "style": "IPY_MODEL_3feaf01a7f7b43ed923effab61b93ac4",
       "value": " 36473/36473 [00:03&lt;00:00, 12012.58it/s]"
      }
     },
     "1c5d07635bff4f7999e3e8486f648aaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87214ce12c1f422481a0fe3caf5a3ce8",
       "max": 2464616,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d9f0d96d140a4115aadfdfc9ce5ba608",
       "value": 2464616
      }
     },
     "1d83ae8940534922833de4d1fdd71216": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2373dbe30aca4d64b94b5bb64216151e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "251e902150c543d2a2212b4250931617": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7d211c0746b64a0b935fa964ad7bd858",
        "IPY_MODEL_432a848a161c4a0888dad1ac9c5408c3",
        "IPY_MODEL_181ebde2d0064fb99b8ec32e9dc76836"
       ],
       "layout": "IPY_MODEL_5d82f1a2cf554609ba65dfb95dc152e5"
      }
     },
     "2866d577bb3049b283da7c969f175d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_673fb48e7dca47f4a3754d06af7dcf1f",
        "IPY_MODEL_bba517b096dd460cb764ccd71b57f148",
        "IPY_MODEL_362ef79e65894ea9aaae390562257f58"
       ],
       "layout": "IPY_MODEL_9d403276e05f4c368e46f353070b9d9a"
      }
     },
     "291ab6d32ec345ee8adaa6f354bfcfb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_12d0d3a78caf4f8c93da02229f2185df",
       "placeholder": "​",
       "style": "IPY_MODEL_de3e60ed24f04a7ab49a05b98b7cf0f0",
       "value": " 36473/36473 [00:03&lt;00:00, 7261.90it/s]"
      }
     },
     "341389680b6a43d8b6b3de95dffca671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "349e43c8d4114c36823434cef63fc567": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "35cb92ba1b2d4932bc3a0b0640f71b0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "360314d0f3254b66818b8a62223c2b0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "362ef79e65894ea9aaae390562257f58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e94a902a0d44b1eacfaeee99cd470d2",
       "placeholder": "​",
       "style": "IPY_MODEL_ad6386dafce545c48eac271bb2a3c0dd",
       "value": " 136/136 [00:00&lt;00:00, 2149.45it/s]"
      }
     },
     "39512e7ede884ec1b6fe92f794e1d74d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b0ebe22bd154b01bcb4d6b2ab2dec83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad4745f1eca942009bdf6cf12913f34a",
       "placeholder": "​",
       "style": "IPY_MODEL_d3b6e4a4aac943b79ba51bbacd77907e",
       "value": " 2.35M/2.35M [00:00&lt;00:00, 4.49MB/s]"
      }
     },
     "3e601d15c9ef4bd1b05e70f9267e1dfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3feaf01a7f7b43ed923effab61b93ac4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4133e3e34f97426c9bebda989ec7e167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_48b36757767f4ff39f262dd63e844057",
        "IPY_MODEL_a03e24ff8fc54bccaa69e36839b36bab",
        "IPY_MODEL_e3e17f880bab4d47a1531bebac861fda"
       ],
       "layout": "IPY_MODEL_da88817e8aed48399b1948f8e004ee97"
      }
     },
     "43014906a0084e288ab06cb3ebf57538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_968e2989cea6490d9ee08b6700291242",
       "placeholder": "​",
       "style": "IPY_MODEL_929108014ee94c9092394cf7ef09134f",
       "value": "Downloading: 100%"
      }
     },
     "432a848a161c4a0888dad1ac9c5408c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39512e7ede884ec1b6fe92f794e1d74d",
       "max": 36473,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_466a744f951d433da986e75bc9fd3b69",
       "value": 36473
      }
     },
     "466a744f951d433da986e75bc9fd3b69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "46ab7441760642718f381e7f430e16a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "48b36757767f4ff39f262dd63e844057": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14972cafd36646939e742a987e1d0ec7",
       "placeholder": "​",
       "style": "IPY_MODEL_3e601d15c9ef4bd1b05e70f9267e1dfe",
       "value": "Downloading: 100%"
      }
     },
     "4c514a00a080445da009d272716b3577": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81b1213eb9dc4aa083951352d9f6beaf",
       "placeholder": "​",
       "style": "IPY_MODEL_7603cb9268524ed3821b4f307f74d15e",
       "value": "Downloading: 100%"
      }
     },
     "4e94a902a0d44b1eacfaeee99cd470d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5235854cc7964193afec8b3316b36ef7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_58c973b1ea8a446e9993f32d3612c8b9",
        "IPY_MODEL_b849e52bd84942e583de4b9325c96afe",
        "IPY_MODEL_291ab6d32ec345ee8adaa6f354bfcfb4"
       ],
       "layout": "IPY_MODEL_fb6b7fc69b2549ab9d80d71017422178"
      }
     },
     "58c973b1ea8a446e9993f32d3612c8b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_360314d0f3254b66818b8a62223c2b0b",
       "placeholder": "​",
       "style": "IPY_MODEL_c5de80b22af543edb57e65780298069e",
       "value": "100%"
      }
     },
     "5a2b3274110a42159fcfb2e01ceea10a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_43014906a0084e288ab06cb3ebf57538",
        "IPY_MODEL_1c5d07635bff4f7999e3e8486f648aaf",
        "IPY_MODEL_3b0ebe22bd154b01bcb4d6b2ab2dec83"
       ],
       "layout": "IPY_MODEL_2373dbe30aca4d64b94b5bb64216151e"
      }
     },
     "5d82f1a2cf554609ba65dfb95dc152e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ffb53b010e948a0918366a7721dd7a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aaf4c8e1ae794178bd2db64c5c27edcd",
       "placeholder": "​",
       "style": "IPY_MODEL_ff0d93c0f2a54cae8698028db31d1454",
       "value": "0.065 MB of 0.065 MB uploaded (0.000 MB deduped)\r"
      }
     },
     "65f9dfd885184f818373dcaf8b820da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "673fb48e7dca47f4a3754d06af7dcf1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_749c407f4aa34689954d06117f699f3c",
       "placeholder": "​",
       "style": "IPY_MODEL_bb944cd3fb694105a4d535f4e9c333a8",
       "value": "100%"
      }
     },
     "6947506e822e46d99b4dd82a8a4209cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "749c407f4aa34689954d06117f699f3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7603cb9268524ed3821b4f307f74d15e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7d211c0746b64a0b935fa964ad7bd858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f836cfd56e0d4d7188f1b263a5845bff",
       "placeholder": "​",
       "style": "IPY_MODEL_a87f939ae9cb44bf8d9eed523f5cb995",
       "value": "100%"
      }
     },
     "7fb6ee0e688440bab23c07808e5cef8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0dcc3eeec934d289bf99c7d14bab090",
       "max": 873673253,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c4ff773d63e34e0c93e23aa455a97958",
       "value": 873673253
      }
     },
     "80f827d24b2e421bbe84d92c8dcc002b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81b1213eb9dc4aa083951352d9f6beaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82f268442b1349268246323595e0f371": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4c514a00a080445da009d272716b3577",
        "IPY_MODEL_b4e52efc58b54c81a39fa8e5fc26eedd",
        "IPY_MODEL_a1cafe17bdf945aa8a33875d0590f7a2"
       ],
       "layout": "IPY_MODEL_65f9dfd885184f818373dcaf8b820da7"
      }
     },
     "842a840396ab4cefb93cc2733bf00cf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "86af7db3cea442beb67da28063f15ed6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_be8bbaca794c4ab0b387c44fc3d2637f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_126a1e5f24e44838a03204815209c5dc",
       "value": 1
      }
     },
     "87214ce12c1f422481a0fe3caf5a3ce8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "874dcbcfa5c94b938abebb1c7d00007c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ae7b72a5b9f4533a2076af3fb7786bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "929108014ee94c9092394cf7ef09134f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "968e2989cea6490d9ee08b6700291242": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9901f18e7e5841b8bfcb918c432ef718": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d403276e05f4c368e46f353070b9d9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a03e24ff8fc54bccaa69e36839b36bab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80f827d24b2e421bbe84d92c8dcc002b",
       "max": 580,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_349e43c8d4114c36823434cef63fc567",
       "value": 580
      }
     },
     "a1cafe17bdf945aa8a33875d0590f7a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd68281fe7ea499882e5d23a5bbfb9f0",
       "placeholder": "​",
       "style": "IPY_MODEL_8ae7b72a5b9f4533a2076af3fb7786bd",
       "value": " 52.0/52.0 [00:00&lt;00:00, 2.03kB/s]"
      }
     },
     "a3f3db4032b54ac49421d5cbd31a9533": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a87f939ae9cb44bf8d9eed523f5cb995": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aaf4c8e1ae794178bd2db64c5c27edcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab615699cb634117a739e8673396b52d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ad4745f1eca942009bdf6cf12913f34a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad6386dafce545c48eac271bb2a3c0dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4e52efc58b54c81a39fa8e5fc26eedd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6947506e822e46d99b4dd82a8a4209cd",
       "max": 52,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_874dcbcfa5c94b938abebb1c7d00007c",
       "value": 52
      }
     },
     "b6f3605957844ac0b026ef0593befbae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b849e52bd84942e583de4b9325c96afe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_341389680b6a43d8b6b3de95dffca671",
       "max": 36473,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab615699cb634117a739e8673396b52d",
       "value": 36473
      }
     },
     "ba8f6b6e291a4d6faae41e5e6921f4aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb944cd3fb694105a4d535f4e9c333a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bba517b096dd460cb764ccd71b57f148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ba8f6b6e291a4d6faae41e5e6921f4aa",
       "max": 136,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ec381745899e4ce7900c973c72d2ff3b",
       "value": 136
      }
     },
     "be8bbaca794c4ab0b387c44fc3d2637f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0dcc3eeec934d289bf99c7d14bab090": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1e8e53062324cf38fbd75eab01e066a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4ff773d63e34e0c93e23aa455a97958": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c5de80b22af543edb57e65780298069e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d21724e187b94518ad3cc61f1daa73cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e13e1ad96b5648588ba7a5b2e3771179",
        "IPY_MODEL_7fb6ee0e688440bab23c07808e5cef8b",
        "IPY_MODEL_f9081778edc6436c9d1bc9a886ac922c"
       ],
       "layout": "IPY_MODEL_9901f18e7e5841b8bfcb918c432ef718"
      }
     },
     "d3b6e4a4aac943b79ba51bbacd77907e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d9f0d96d140a4115aadfdfc9ce5ba608": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "da88817e8aed48399b1948f8e004ee97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd68281fe7ea499882e5d23a5bbfb9f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de3e60ed24f04a7ab49a05b98b7cf0f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e13e1ad96b5648588ba7a5b2e3771179": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d83ae8940534922833de4d1fdd71216",
       "placeholder": "​",
       "style": "IPY_MODEL_46ab7441760642718f381e7f430e16a0",
       "value": "Downloading: 100%"
      }
     },
     "e3e17f880bab4d47a1531bebac861fda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a3f3db4032b54ac49421d5cbd31a9533",
       "placeholder": "​",
       "style": "IPY_MODEL_35cb92ba1b2d4932bc3a0b0640f71b0c",
       "value": " 580/580 [00:00&lt;00:00, 23.1kB/s]"
      }
     },
     "ec381745899e4ce7900c973c72d2ff3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3e6058e180d40b8bc25ff82940789f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7cdf444f3c041cda9b6bd5a47ca87c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5ffb53b010e948a0918366a7721dd7a9",
        "IPY_MODEL_86af7db3cea442beb67da28063f15ed6"
       ],
       "layout": "IPY_MODEL_b6f3605957844ac0b026ef0593befbae"
      }
     },
     "f836cfd56e0d4d7188f1b263a5845bff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9081778edc6436c9d1bc9a886ac922c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f3e6058e180d40b8bc25ff82940789f1",
       "placeholder": "​",
       "style": "IPY_MODEL_842a840396ab4cefb93cc2733bf00cf7",
       "value": " 833M/833M [00:19&lt;00:00, 43.1MB/s]"
      }
     },
     "fb6b7fc69b2549ab9d80d71017422178": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff0d93c0f2a54cae8698028db31d1454": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
