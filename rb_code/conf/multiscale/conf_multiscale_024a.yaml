debug: false
use_random_seed: true
seed: 461

fold: ???
train_folds: ???
valid_folds: ???

use_wandb: false
all_data: false

tags:
  - debv3_large
  - multi-scale

model:
  backbone_path: microsoft/deberta-v3-large
  num_layers_reinit: 2
  head:
    num_layers: 4
  n_freeze: 22
  max_length: 768
  target_names:
    - cohesion
    - syntax
    - vocabulary
    - phraseology
    - grammar
    - conventions
  loss_fn: mse
  add_new_tokens: true
  load_from_ckpt: false
  ckpt_path: ???
  len_tokenizer: ???
  use_sim_loss: true
  use_ranking_loss: true

train_params:
  train_bs: 8
  valid_bs: 16
  grad_accumulation: 1
  warmup_pct: 0.05
  num_epochs: 7 # 6
  eval_frequency: 120
  full_eval_start_epoch: 0
  save_trigger: 1.0
  patience: 20
  use_ema: true
  use_fp16: true

optimizer:
  decoder_lr: 5e-5 # 1.25e-5
  encoder_lr: 5e-5 # 1.25e-5
  weight_decay: 2e-4
  eps: 1e-6
  beta1: 0.9
  beta2: 0.999
  grad_clip: 10
  use_bnb: true
  use_llrd: true
  llrd: 0.9

awp:
  use_awp: true
  awp_trigger: 5.0
  awp_trigger_epoch: 1
  adv_lr: 8e-5
  adv_eps: 0.001

outputs:
  model_dir: ../models/multi_scale

fold_metadata:
  n_folds: 4
  fold_dir: ../datasets/fold_split
  fold_path: "cv_map_${fold_metadata.n_folds}_folds.parquet"


competition_dataset:
  data_dir: ../datasets/feedback-prize-english-language-learning
  train_path: train.csv
  test_path: test.csv

ensemble_pl:
  use_pl: false
  pl_raw_path: na
  num_pl_samples: na
  num_pl_epochs: na
  pl_paths: na

wandb:
  entity: kaggle-clrp
  project: rb-feedback-ells-dev-a1
  run_name: rb-exp035-multi-scale-reinit-ranking


