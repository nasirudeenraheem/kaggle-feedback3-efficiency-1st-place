dataset:
  path: ...
  fold_file: ../../input/fb3_folds.csv
  n_samples_in_train: 0

model:
  path: /media/heyao/42f00068-ba8d-48dd-8719-61eda5244b8d/pretrained-models/deberta-v3-base
  pooling: attention
  msd: false
  num_reinit_layers: 1
  residual_transformers: false
  differential_lr:
    enable: true
    lr_factor: 2.6

optim:
  optimizer:
    lr: 5e-5
    head_lr: 1e-3
    betas: [0.9, 0.999]
    eps: 1e-6
    weight_decay: 1e-2
  scheduler:
    name: linear
    num_warmup_steps: 0
    kwargs: {}

train:
  device: gpu
  num_folds: 5
  fold_index: [0]
  random_seed: 42
  ensure_data_order: true
  reinit_weights: true
  loss: mcrmse
  # whether to use `resolve_encodings_and_normalize`
  clean: true
  zero_dropout: true
  max_length: 512
  batch_size: 16
  epochs: 4
  num_workers: 0
  accumulate_grad: 1
  max_grad_norm: 1000
  validation_interval: .5
  precision: 16
  gradient_checkpointing: true
  freeze_embeddings: false
  freeze_encoders: 0
  trained_target: false

  report_to:
    tensorboard:
      enable: true
      path: ./tf-logs
    wandb:
      enable: false

  mixout:
    enable: false

  multi_task:
    enable: false

  pl:
    enable: false

  ema:
    enable: false
