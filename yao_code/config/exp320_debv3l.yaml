dataset:
  path: '...'
  fold_file: /home/heyao/kaggle/feedback-ells/input/fb3_folds/train_8folds.csv
  n_samples_in_train: 3422
  most_similar_sample_path: /home/heyao/kaggle/feedback-ells/input/real_similar_indexes_{train}_fold{fold}_{n_folds}.json
  train_bm25_path: /home/heyao/kaggle/feedback-ells/input/all_data_bm25.npz.npy
model:
  path: /media/heyao/42f00068-ba8d-48dd-8719-61eda5244b8d/pretrained-models/deberta-v3-large
  type: regression
  head: ''
  pooling: lstm_meanmax
  layer_start: 12
  residual_transformers: false
  msd: false
  num_reinit_layers: 1
  differential_lr:
    enable: true
    lr_factor: 2.6
optim:
  optimizer:
    lookahead: false
    lr: 1.0e-05
    head_lr: 0.0005
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-06
    weight_decay: 0.01
  scheduler:
    name: cosine
    num_warmup_steps: 100
    kwargs: {}
train:
  device: gpu
  num_folds: 8
  fold_index:
  - 7
  random_seed: 42
  ensure_data_order: true
  reinit_weights: true
  loss: mcrmse
  zero_dropout: true
  clean: false
  accumulate_grad: 1
  max_length: 768
  batch_size: 2
  epochs: 4
  num_workers: 12
  max_grad_norm: 10
  validation_interval: 0.5
  precision: 16
  gradient_checkpointing: true
  freeze_embeddings: false
  freeze_encoders: 0
  report_to:
    tensorboard:
      enable: true
      path: /home/heyao/tf-logs
    wandb:
      enable: false
  awp:
    enable: false
    from_score: 0.48
    adv_param: weight
    adv_lr: 1
    adv_eps: 0.01
    start_epoch: 1
    adv_step: 1
  ema:
    enable: false
    from_score: 100
    decay: 0.999
  mixout:
    enable: false
    p: 0.1
  multi_task:
    enable: false
    weight: 0.8
    tasks:
    - total_error_ratio
    - grammar_error_ratio
    path: /home/heyao/kaggle/feedback-english-lan-learning/input/tasks/fb3_readability.csv
  pl:
    enable: false
    path: /home/heyao/kaggle/feedback-english-lan-learning/output/pl/pl_dbv3l_fold{fold}.csv
    stage: 1
    prev_model_path: /home/heyao/kaggle/feedback-english-lan-learning/bin/weights/deberta-v3-large_fold{fold}-v2.ckpt
  trained_target: null
  save_config: true
tokenizer:
  label_token_ids:
  - - 31066
  - - 16843
  - - 11174
  - - 5741
    - 8495
  - - 10877
  - - 15521
  label_start_id: 128001
  label_end_id: 128006
  label_inject: false
  label_positions:
  - 4
  - 6
  - 8
  - 10
  - 11
  - 15
